The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `8`
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-01-16:16:33:26,510 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:16:33:26,510 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:16:33:26,510 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:16:33:26,510 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:16:33:26,525 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:16:33:26,526 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:16:33:26,533 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:16:33:26,534 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:16:33:26,536 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:16:33:26,537 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:16:33:26,581 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:16:33:26,581 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:16:33:26,586 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:16:33:26,587 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:16:33:26,594 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:16:33:26,594 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:16:33:27,060 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:16:33:27,119 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:16:33:27,132 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:16:33:27,133 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:16:33:27,147 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:16:33:27,151 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:16:33:27,154 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:16:33:27,189 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:16:33:31,700 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:16:33:31,700 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:16:33:31,725 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:16:33:31,740 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:16:33:31,743 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:16:33:31,747 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:16:33:31,770 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:16:33:31,778 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:16:33:38,532 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:16:33:38,533 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:16:33:38,784 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:16:33:38,817 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:16:33:38,830 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:16:33:39,059 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:16:33:39,238 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:16:33:39,671 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:16:34:34,878 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:16:34:34,884 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:16:34:36,373 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:16:34:36,378 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:16:34:36,464 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:16:34:36,468 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:16:34:36,539 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:16:34:36,543 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:16:34:36,803 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:16:34:36,807 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:16:34:36,947 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:16:34:36,951 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:16:34:37,132 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:16:34:37,137 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:16:34:38,127 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:16:34:38,131 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
config.json:   0%|          | 0.00/719 [00:00<?, ?B/s]config.json: 100%|██████████| 719/719 [00:00<00:00, 3.26MB/s]
pytorch_model.bin:   0%|          | 0.00/4.05G [00:00<?, ?B/s]pytorch_model.bin:   0%|          | 10.5M/4.05G [00:00<00:58, 69.0MB/s]pytorch_model.bin:   1%|          | 21.0M/4.05G [00:00<00:54, 74.5MB/s]pytorch_model.bin:   1%|          | 31.5M/4.05G [00:00<00:51, 78.4MB/s]pytorch_model.bin:   1%|          | 41.9M/4.05G [00:00<00:50, 79.8MB/s]pytorch_model.bin:   1%|▏         | 52.4M/4.05G [00:00<00:48, 81.9MB/s]pytorch_model.bin:   2%|▏         | 62.9M/4.05G [00:00<00:48, 82.0MB/s]pytorch_model.bin:   2%|▏         | 73.4M/4.05G [00:00<00:48, 82.5MB/s]pytorch_model.bin:   2%|▏         | 83.9M/4.05G [00:01<00:47, 82.9MB/s]pytorch_model.bin:   2%|▏         | 94.4M/4.05G [00:01<00:47, 82.4MB/s]pytorch_model.bin:   3%|▎         | 105M/4.05G [00:01<00:47, 82.7MB/s] pytorch_model.bin:   3%|▎         | 115M/4.05G [00:01<00:47, 83.4MB/s]pytorch_model.bin:   3%|▎         | 126M/4.05G [00:01<00:47, 83.2MB/s]pytorch_model.bin:   3%|▎         | 136M/4.05G [00:01<00:46, 83.2MB/s]pytorch_model.bin:   4%|▎         | 147M/4.05G [00:01<00:47, 81.7MB/s]pytorch_model.bin:   4%|▍         | 157M/4.05G [00:01<00:47, 81.5MB/s]pytorch_model.bin:   4%|▍         | 168M/4.05G [00:02<00:49, 77.9MB/s]pytorch_model.bin:   4%|▍         | 178M/4.05G [00:02<00:48, 79.7MB/s]pytorch_model.bin:   5%|▍         | 189M/4.05G [00:02<00:48, 80.2MB/s]pytorch_model.bin:   5%|▍         | 199M/4.05G [00:02<00:47, 80.9MB/s]pytorch_model.bin:   5%|▌         | 210M/4.05G [00:02<00:46, 81.8MB/s]pytorch_model.bin:   5%|▌         | 220M/4.05G [00:02<00:46, 82.1MB/s]pytorch_model.bin:   6%|▌         | 231M/4.05G [00:02<00:46, 82.2MB/s]pytorch_model.bin:   6%|▌         | 241M/4.05G [00:02<00:46, 82.6MB/s]pytorch_model.bin:   6%|▌         | 252M/4.05G [00:03<00:45, 82.7MB/s]pytorch_model.bin:   6%|▋         | 262M/4.05G [00:03<00:45, 82.9MB/s]pytorch_model.bin:   7%|▋         | 273M/4.05G [00:03<00:45, 82.3MB/s]pytorch_model.bin:   7%|▋         | 283M/4.05G [00:03<00:45, 82.8MB/s]pytorch_model.bin:   7%|▋         | 294M/4.05G [00:03<00:45, 82.6MB/s]pytorch_model.bin:   8%|▊         | 304M/4.05G [00:03<00:44, 83.3MB/s]pytorch_model.bin:   8%|▊         | 315M/4.05G [00:03<00:44, 83.3MB/s]pytorch_model.bin:   8%|▊         | 325M/4.05G [00:03<00:45, 82.3MB/s]pytorch_model.bin:   8%|▊         | 336M/4.05G [00:04<00:45, 81.9MB/s]pytorch_model.bin:   9%|▊         | 346M/4.05G [00:04<00:44, 82.7MB/s]pytorch_model.bin:   9%|▉         | 357M/4.05G [00:04<00:44, 82.8MB/s]pytorch_model.bin:   9%|▉         | 367M/4.05G [00:04<00:44, 82.9MB/s]pytorch_model.bin:   9%|▉         | 377M/4.05G [00:04<00:44, 83.2MB/s]pytorch_model.bin:  10%|▉         | 388M/4.05G [00:04<00:43, 83.3MB/s]pytorch_model.bin:  10%|▉         | 398M/4.05G [00:04<00:43, 82.9MB/s]pytorch_model.bin:  10%|█         | 409M/4.05G [00:04<00:43, 82.8MB/s]pytorch_model.bin:  10%|█         | 419M/4.05G [00:05<00:43, 83.1MB/s]pytorch_model.bin:  11%|█         | 430M/4.05G [00:05<00:43, 82.8MB/s]pytorch_model.bin:  11%|█         | 440M/4.05G [00:05<00:43, 82.8MB/s]pytorch_model.bin:  11%|█         | 451M/4.05G [00:05<00:43, 83.1MB/s]pytorch_model.bin:  11%|█▏        | 461M/4.05G [00:05<00:43, 82.3MB/s]pytorch_model.bin:  12%|█▏        | 472M/4.05G [00:05<00:43, 83.1MB/s]pytorch_model.bin:  12%|█▏        | 482M/4.05G [00:05<00:42, 83.2MB/s]pytorch_model.bin:  12%|█▏        | 493M/4.05G [00:06<00:42, 83.2MB/s]pytorch_model.bin:  12%|█▏        | 503M/4.05G [00:06<00:42, 82.9MB/s]pytorch_model.bin:  13%|█▎        | 514M/4.05G [00:06<00:42, 82.9MB/s]pytorch_model.bin:  13%|█▎        | 524M/4.05G [00:06<00:42, 83.0MB/s]pytorch_model.bin:  13%|█▎        | 535M/4.05G [00:06<00:42, 83.1MB/s]pytorch_model.bin:  13%|█▎        | 545M/4.05G [00:06<00:42, 83.0MB/s]pytorch_model.bin:  14%|█▎        | 556M/4.05G [00:06<00:42, 82.9MB/s]pytorch_model.bin:  14%|█▍        | 566M/4.05G [00:06<00:42, 82.7MB/s]pytorch_model.bin:  14%|█▍        | 577M/4.05G [00:07<00:41, 82.9MB/s]pytorch_model.bin:  15%|█▍        | 587M/4.05G [00:07<00:41, 82.6MB/s]pytorch_model.bin:  15%|█▍        | 598M/4.05G [00:07<00:41, 83.1MB/s]pytorch_model.bin:  15%|█▌        | 608M/4.05G [00:07<00:41, 83.1MB/s]pytorch_model.bin:  15%|█▌        | 619M/4.05G [00:07<00:41, 83.1MB/s]pytorch_model.bin:  16%|█▌        | 629M/4.05G [00:07<00:41, 82.1MB/s]pytorch_model.bin:  16%|█▌        | 640M/4.05G [00:07<00:41, 82.3MB/s]pytorch_model.bin:  16%|█▌        | 650M/4.05G [00:07<00:41, 82.5MB/s]pytorch_model.bin:  16%|█▋        | 661M/4.05G [00:08<00:41, 82.1MB/s]pytorch_model.bin:  17%|█▋        | 671M/4.05G [00:08<00:41, 82.3MB/s]pytorch_model.bin:  17%|█▋        | 682M/4.05G [00:08<00:40, 82.3MB/s]pytorch_model.bin:  17%|█▋        | 692M/4.05G [00:08<00:40, 82.0MB/s]pytorch_model.bin:  17%|█▋        | 703M/4.05G [00:08<00:40, 82.3MB/s]pytorch_model.bin:  18%|█▊        | 713M/4.05G [00:08<00:40, 82.7MB/s]pytorch_model.bin:  18%|█▊        | 724M/4.05G [00:08<00:40, 82.9MB/s]pytorch_model.bin:  18%|█▊        | 734M/4.05G [00:08<00:39, 82.9MB/s]pytorch_model.bin:  18%|█▊        | 744M/4.05G [00:09<00:39, 83.1MB/s]pytorch_model.bin:  19%|█▊        | 755M/4.05G [00:09<00:39, 83.1MB/s]pytorch_model.bin:  19%|█▉        | 765M/4.05G [00:09<00:39, 83.1MB/s]pytorch_model.bin:  19%|█▉        | 776M/4.05G [00:09<00:39, 82.8MB/s]pytorch_model.bin:  19%|█▉        | 786M/4.05G [00:09<00:39, 82.5MB/s]pytorch_model.bin:  20%|█▉        | 797M/4.05G [00:09<00:39, 82.4MB/s]pytorch_model.bin:  20%|█▉        | 807M/4.05G [00:09<00:41, 78.8MB/s]pytorch_model.bin:  20%|██        | 818M/4.05G [00:09<00:40, 79.8MB/s]pytorch_model.bin:  20%|██        | 828M/4.05G [00:10<00:40, 79.0MB/s]pytorch_model.bin:  21%|██        | 839M/4.05G [00:10<00:39, 81.7MB/s]pytorch_model.bin:  21%|██        | 849M/4.05G [00:10<00:39, 81.8MB/s]pytorch_model.bin:  21%|██        | 860M/4.05G [00:10<00:38, 82.4MB/s]pytorch_model.bin:  22%|██▏       | 870M/4.05G [00:10<00:38, 82.5MB/s]pytorch_model.bin:  22%|██▏       | 881M/4.05G [00:10<00:38, 82.3MB/s]pytorch_model.bin:  22%|██▏       | 891M/4.05G [00:10<00:37, 83.1MB/s]pytorch_model.bin:  22%|██▏       | 902M/4.05G [00:10<00:40, 76.9MB/s]pytorch_model.bin:  23%|██▎       | 912M/4.05G [00:11<00:44, 70.9MB/s]pytorch_model.bin:  23%|██▎       | 933M/4.05G [00:11<00:36, 84.9MB/s]pytorch_model.bin:  23%|██▎       | 944M/4.05G [00:11<00:40, 75.9MB/s]pytorch_model.bin:  24%|██▍       | 965M/4.05G [00:11<00:34, 89.7MB/s]pytorch_model.bin:  24%|██▍       | 975M/4.05G [00:11<00:34, 87.9MB/s]pytorch_model.bin:  24%|██▍       | 986M/4.05G [00:11<00:35, 87.0MB/s]pytorch_model.bin:  25%|██▍       | 996M/4.05G [00:12<00:35, 85.4MB/s]pytorch_model.bin:  25%|██▍       | 1.01G/4.05G [00:12<00:35, 85.2MB/s]pytorch_model.bin:  25%|██▌       | 1.02G/4.05G [00:12<00:35, 84.8MB/s]pytorch_model.bin:  25%|██▌       | 1.03G/4.05G [00:12<00:35, 84.3MB/s]pytorch_model.bin:  26%|██▌       | 1.04G/4.05G [00:12<00:36, 83.2MB/s]pytorch_model.bin:  26%|██▌       | 1.05G/4.05G [00:12<00:35, 84.1MB/s]pytorch_model.bin:  26%|██▌       | 1.06G/4.05G [00:12<00:35, 83.5MB/s]pytorch_model.bin:  26%|██▋       | 1.07G/4.05G [00:12<00:35, 83.5MB/s]pytorch_model.bin:  27%|██▋       | 1.08G/4.05G [00:13<00:35, 83.3MB/s]pytorch_model.bin:  27%|██▋       | 1.09G/4.05G [00:13<00:35, 83.2MB/s]pytorch_model.bin:  27%|██▋       | 1.10G/4.05G [00:13<00:35, 83.1MB/s]pytorch_model.bin:  27%|██▋       | 1.11G/4.05G [00:13<00:35, 82.3MB/s]pytorch_model.bin:  28%|██▊       | 1.12G/4.05G [00:13<00:35, 83.4MB/s]pytorch_model.bin:  28%|██▊       | 1.13G/4.05G [00:13<00:34, 83.5MB/s]pytorch_model.bin:  28%|██▊       | 1.14G/4.05G [00:13<00:35, 82.2MB/s]pytorch_model.bin:  28%|██▊       | 1.15G/4.05G [00:13<00:34, 83.7MB/s]pytorch_model.bin:  29%|██▉       | 1.16G/4.05G [00:14<00:34, 83.1MB/s]pytorch_model.bin:  29%|██▉       | 1.17G/4.05G [00:14<00:34, 82.7MB/s]pytorch_model.bin:  29%|██▉       | 1.18G/4.05G [00:14<00:37, 76.8MB/s]pytorch_model.bin:  30%|██▉       | 1.21G/4.05G [00:14<00:33, 84.4MB/s]pytorch_model.bin:  30%|███       | 1.22G/4.05G [00:14<00:34, 81.8MB/s]pytorch_model.bin:  30%|███       | 1.23G/4.05G [00:14<00:34, 82.1MB/s]pytorch_model.bin:  31%|███       | 1.24G/4.05G [00:15<00:34, 82.3MB/s]pytorch_model.bin:  31%|███       | 1.25G/4.05G [00:15<00:33, 82.4MB/s]pytorch_model.bin:  31%|███       | 1.26G/4.05G [00:15<00:33, 82.8MB/s]pytorch_model.bin:  31%|███▏      | 1.27G/4.05G [00:15<00:33, 83.0MB/s]pytorch_model.bin:  32%|███▏      | 1.28G/4.05G [00:15<00:33, 82.3MB/s]pytorch_model.bin:  32%|███▏      | 1.29G/4.05G [00:15<00:34, 81.0MB/s]pytorch_model.bin:  32%|███▏      | 1.30G/4.05G [00:15<00:33, 81.5MB/s]pytorch_model.bin:  32%|███▏      | 1.31G/4.05G [00:15<00:33, 81.8MB/s]pytorch_model.bin:  33%|███▎      | 1.32G/4.05G [00:16<00:33, 82.4MB/s]pytorch_model.bin:  33%|███▎      | 1.33G/4.05G [00:16<00:32, 82.6MB/s]pytorch_model.bin:  33%|███▎      | 1.34G/4.05G [00:16<00:32, 82.7MB/s]pytorch_model.bin:  33%|███▎      | 1.35G/4.05G [00:16<00:33, 81.0MB/s]pytorch_model.bin:  34%|███▎      | 1.36G/4.05G [00:16<00:32, 83.7MB/s]pytorch_model.bin:  34%|███▍      | 1.37G/4.05G [00:16<00:31, 83.6MB/s]pytorch_model.bin:  34%|███▍      | 1.38G/4.05G [00:16<00:31, 83.4MB/s]pytorch_model.bin:  34%|███▍      | 1.39G/4.05G [00:16<00:31, 83.3MB/s]pytorch_model.bin:  35%|███▍      | 1.41G/4.05G [00:17<00:31, 83.0MB/s]pytorch_model.bin:  35%|███▍      | 1.42G/4.05G [00:17<00:31, 82.8MB/s]pytorch_model.bin:  35%|███▌      | 1.43G/4.05G [00:17<00:31, 83.1MB/s]pytorch_model.bin:  35%|███▌      | 1.44G/4.05G [00:17<00:31, 82.8MB/s]pytorch_model.bin:  36%|███▌      | 1.45G/4.05G [00:17<00:31, 83.2MB/s]pytorch_model.bin:  36%|███▌      | 1.46G/4.05G [00:17<00:31, 83.3MB/s]pytorch_model.bin:  36%|███▋      | 1.47G/4.05G [00:17<00:30, 83.2MB/s]pytorch_model.bin:  37%|███▋      | 1.48G/4.05G [00:17<00:30, 83.2MB/s]pytorch_model.bin:  37%|███▋      | 1.49G/4.05G [00:18<00:30, 83.1MB/s]pytorch_model.bin:  37%|███▋      | 1.50G/4.05G [00:18<00:30, 82.9MB/s]pytorch_model.bin:  37%|███▋      | 1.51G/4.05G [00:18<00:30, 82.5MB/s]pytorch_model.bin:  38%|███▊      | 1.52G/4.05G [00:18<00:30, 82.5MB/s]pytorch_model.bin:  38%|███▊      | 1.53G/4.05G [00:18<00:30, 82.9MB/s]pytorch_model.bin:  38%|███▊      | 1.54G/4.05G [00:18<00:30, 82.5MB/s]pytorch_model.bin:  38%|███▊      | 1.55G/4.05G [00:18<00:30, 83.0MB/s]pytorch_model.bin:  39%|███▊      | 1.56G/4.05G [00:18<00:30, 82.4MB/s]pytorch_model.bin:  39%|███▉      | 1.57G/4.05G [00:19<00:29, 83.4MB/s]pytorch_model.bin:  39%|███▉      | 1.58G/4.05G [00:19<00:30, 81.4MB/s]pytorch_model.bin:  39%|███▉      | 1.59G/4.05G [00:19<00:29, 84.0MB/s]pytorch_model.bin:  40%|███▉      | 1.60G/4.05G [00:19<00:29, 83.5MB/s]pytorch_model.bin:  40%|███▉      | 1.61G/4.05G [00:19<00:29, 82.9MB/s]pytorch_model.bin:  40%|████      | 1.63G/4.05G [00:19<00:29, 82.7MB/s]pytorch_model.bin:  40%|████      | 1.64G/4.05G [00:19<00:29, 82.6MB/s]pytorch_model.bin:  41%|████      | 1.65G/4.05G [00:19<00:29, 82.3MB/s]pytorch_model.bin:  41%|████      | 1.66G/4.05G [00:20<00:28, 82.9MB/s]pytorch_model.bin:  41%|████      | 1.67G/4.05G [00:20<00:28, 82.9MB/s]pytorch_model.bin:  41%|████▏     | 1.68G/4.05G [00:20<00:28, 82.9MB/s]pytorch_model.bin:  42%|████▏     | 1.69G/4.05G [00:20<00:28, 83.0MB/s]pytorch_model.bin:  42%|████▏     | 1.70G/4.05G [00:20<00:28, 83.1MB/s]pytorch_model.bin:  42%|████▏     | 1.71G/4.05G [00:20<00:28, 83.0MB/s]pytorch_model.bin:  42%|████▏     | 1.72G/4.05G [00:20<00:28, 82.5MB/s]pytorch_model.bin:  43%|████▎     | 1.73G/4.05G [00:20<00:28, 82.6MB/s]pytorch_model.bin:  43%|████▎     | 1.74G/4.05G [00:21<00:28, 81.6MB/s]pytorch_model.bin:  43%|████▎     | 1.75G/4.05G [00:21<00:28, 80.7MB/s]pytorch_model.bin:  44%|████▎     | 1.76G/4.05G [00:21<00:27, 82.5MB/s]pytorch_model.bin:  44%|████▍     | 1.77G/4.05G [00:21<00:27, 82.6MB/s]pytorch_model.bin:  44%|████▍     | 1.78G/4.05G [00:21<00:27, 82.2MB/s]pytorch_model.bin:  44%|████▍     | 1.79G/4.05G [00:21<00:27, 82.3MB/s]pytorch_model.bin:  45%|████▍     | 1.80G/4.05G [00:21<00:28, 78.0MB/s]pytorch_model.bin:  45%|████▍     | 1.81G/4.05G [00:22<00:29, 76.2MB/s]pytorch_model.bin:  45%|████▌     | 1.84G/4.05G [00:22<00:25, 85.5MB/s]pytorch_model.bin:  46%|████▌     | 1.85G/4.05G [00:22<00:26, 83.0MB/s]pytorch_model.bin:  46%|████▌     | 1.86G/4.05G [00:22<00:26, 83.6MB/s]pytorch_model.bin:  46%|████▌     | 1.87G/4.05G [00:22<00:26, 81.2MB/s]pytorch_model.bin:  46%|████▋     | 1.88G/4.05G [00:22<00:26, 81.9MB/s]pytorch_model.bin:  47%|████▋     | 1.89G/4.05G [00:22<00:26, 80.6MB/s]pytorch_model.bin:  47%|████▋     | 1.90G/4.05G [00:23<00:28, 76.5MB/s]pytorch_model.bin:  47%|████▋     | 1.92G/4.05G [00:23<00:27, 77.9MB/s]pytorch_model.bin:  48%|████▊     | 1.94G/4.05G [00:23<00:25, 84.3MB/s]pytorch_model.bin:  48%|████▊     | 1.95G/4.05G [00:23<00:25, 80.8MB/s]pytorch_model.bin:  48%|████▊     | 1.96G/4.05G [00:23<00:24, 84.9MB/s]pytorch_model.bin:  49%|████▊     | 1.97G/4.05G [00:23<00:24, 84.1MB/s]pytorch_model.bin:  49%|████▉     | 1.98G/4.05G [00:24<00:24, 84.1MB/s]pytorch_model.bin:  49%|████▉     | 1.99G/4.05G [00:24<00:24, 84.3MB/s]pytorch_model.bin:  49%|████▉     | 2.00G/4.05G [00:24<00:24, 83.9MB/s]pytorch_model.bin:  50%|████▉     | 2.01G/4.05G [00:24<00:24, 83.5MB/s]pytorch_model.bin:  50%|█████     | 2.02G/4.05G [00:24<00:24, 83.7MB/s]pytorch_model.bin:  50%|█████     | 2.03G/4.05G [00:24<00:24, 83.7MB/s]pytorch_model.bin:  51%|█████     | 2.04G/4.05G [00:24<00:24, 83.2MB/s]pytorch_model.bin:  51%|█████     | 2.06G/4.05G [00:24<00:23, 83.3MB/s]pytorch_model.bin:  51%|█████     | 2.07G/4.05G [00:25<00:23, 83.3MB/s]pytorch_model.bin:  51%|█████▏    | 2.08G/4.05G [00:25<00:23, 83.2MB/s]pytorch_model.bin:  52%|█████▏    | 2.09G/4.05G [00:25<00:23, 83.3MB/s]pytorch_model.bin:  52%|█████▏    | 2.10G/4.05G [00:25<00:24, 78.5MB/s]pytorch_model.bin:  52%|█████▏    | 2.11G/4.05G [00:25<00:22, 84.7MB/s]pytorch_model.bin:  52%|█████▏    | 2.12G/4.05G [00:25<00:23, 82.0MB/s]pytorch_model.bin:  53%|█████▎    | 2.13G/4.05G [00:25<00:22, 84.8MB/s]pytorch_model.bin:  53%|█████▎    | 2.14G/4.05G [00:25<00:22, 84.2MB/s]pytorch_model.bin:  53%|█████▎    | 2.15G/4.05G [00:26<00:22, 83.0MB/s]pytorch_model.bin:  53%|█████▎    | 2.16G/4.05G [00:26<00:22, 83.9MB/s]pytorch_model.bin:  54%|█████▎    | 2.17G/4.05G [00:26<00:22, 83.2MB/s]pytorch_model.bin:  54%|█████▍    | 2.18G/4.05G [00:26<00:23, 80.9MB/s]pytorch_model.bin:  54%|█████▍    | 2.19G/4.05G [00:26<00:22, 83.9MB/s]pytorch_model.bin:  54%|█████▍    | 2.20G/4.05G [00:26<00:21, 83.9MB/s]pytorch_model.bin:  55%|█████▍    | 2.21G/4.05G [00:26<00:21, 83.5MB/s]pytorch_model.bin:  55%|█████▍    | 2.22G/4.05G [00:26<00:21, 83.6MB/s]pytorch_model.bin:  55%|█████▌    | 2.23G/4.05G [00:27<00:21, 83.5MB/s]pytorch_model.bin:  55%|█████▌    | 2.24G/4.05G [00:27<00:21, 82.5MB/s]pytorch_model.bin:  56%|█████▌    | 2.25G/4.05G [00:27<00:21, 83.5MB/s]pytorch_model.bin:  56%|█████▌    | 2.26G/4.05G [00:27<00:21, 83.8MB/s]pytorch_model.bin:  56%|█████▌    | 2.28G/4.05G [00:27<00:21, 83.4MB/s]pytorch_model.bin:  56%|█████▋    | 2.29G/4.05G [00:27<00:21, 81.8MB/s]pytorch_model.bin:  57%|█████▋    | 2.30G/4.05G [00:27<00:21, 83.3MB/s]pytorch_model.bin:  57%|█████▋    | 2.31G/4.05G [00:27<00:20, 83.1MB/s]pytorch_model.bin:  57%|█████▋    | 2.32G/4.05G [00:28<00:20, 82.9MB/s]pytorch_model.bin:  58%|█████▊    | 2.33G/4.05G [00:28<00:20, 82.9MB/s]pytorch_model.bin:  58%|█████▊    | 2.34G/4.05G [00:28<00:21, 81.4MB/s]pytorch_model.bin:  58%|█████▊    | 2.35G/4.05G [00:28<00:20, 81.5MB/s]pytorch_model.bin:  58%|█████▊    | 2.36G/4.05G [00:28<00:20, 82.4MB/s]pytorch_model.bin:  59%|█████▊    | 2.37G/4.05G [00:28<00:20, 82.3MB/s]pytorch_model.bin:  59%|█████▉    | 2.38G/4.05G [00:28<00:20, 81.5MB/s]pytorch_model.bin:  59%|█████▉    | 2.39G/4.05G [00:28<00:20, 82.2MB/s]pytorch_model.bin:  59%|█████▉    | 2.40G/4.05G [00:29<00:20, 80.7MB/s]pytorch_model.bin:  60%|█████▉    | 2.41G/4.05G [00:29<00:20, 81.1MB/s]pytorch_model.bin:  60%|█████▉    | 2.42G/4.05G [00:29<00:19, 81.5MB/s]pytorch_model.bin:  60%|██████    | 2.43G/4.05G [00:29<00:19, 81.7MB/s]pytorch_model.bin:  60%|██████    | 2.44G/4.05G [00:29<00:19, 82.2MB/s]pytorch_model.bin:  61%|██████    | 2.45G/4.05G [00:29<00:19, 82.5MB/s]pytorch_model.bin:  61%|██████    | 2.46G/4.05G [00:29<00:19, 82.6MB/s]pytorch_model.bin:  61%|██████    | 2.47G/4.05G [00:30<00:18, 83.1MB/s]pytorch_model.bin:  61%|██████▏   | 2.49G/4.05G [00:30<00:18, 82.7MB/s]pytorch_model.bin:  62%|██████▏   | 2.50G/4.05G [00:30<00:18, 82.9MB/s]pytorch_model.bin:  62%|██████▏   | 2.51G/4.05G [00:30<00:18, 82.1MB/s]pytorch_model.bin:  62%|██████▏   | 2.52G/4.05G [00:30<00:19, 78.7MB/s]pytorch_model.bin:  62%|██████▏   | 2.53G/4.05G [00:30<00:17, 84.7MB/s]pytorch_model.bin:  63%|██████▎   | 2.54G/4.05G [00:30<00:18, 83.8MB/s]pytorch_model.bin:  63%|██████▎   | 2.55G/4.05G [00:30<00:17, 84.0MB/s]pytorch_model.bin:  63%|██████▎   | 2.56G/4.05G [00:31<00:17, 83.7MB/s]pytorch_model.bin:  63%|██████▎   | 2.57G/4.05G [00:31<00:17, 83.4MB/s]pytorch_model.bin:  64%|██████▎   | 2.58G/4.05G [00:31<00:17, 83.5MB/s]pytorch_model.bin:  64%|██████▍   | 2.59G/4.05G [00:31<00:17, 83.2MB/s]pytorch_model.bin:  64%|██████▍   | 2.60G/4.05G [00:31<00:17, 82.6MB/s]pytorch_model.bin:  65%|██████▍   | 2.61G/4.05G [00:31<00:17, 82.4MB/s]pytorch_model.bin:  65%|██████▍   | 2.62G/4.05G [00:31<00:17, 82.8MB/s]pytorch_model.bin:  65%|██████▌   | 2.63G/4.05G [00:31<00:17, 82.9MB/s]pytorch_model.bin:  65%|██████▌   | 2.64G/4.05G [00:32<00:16, 83.0MB/s]pytorch_model.bin:  66%|██████▌   | 2.65G/4.05G [00:32<00:16, 82.9MB/s]pytorch_model.bin:  66%|██████▌   | 2.66G/4.05G [00:32<00:16, 83.0MB/s]pytorch_model.bin:  66%|██████▌   | 2.67G/4.05G [00:32<00:16, 82.5MB/s]pytorch_model.bin:  66%|██████▋   | 2.68G/4.05G [00:32<00:16, 82.1MB/s]pytorch_model.bin:  67%|██████▋   | 2.69G/4.05G [00:32<00:16, 82.1MB/s]pytorch_model.bin:  67%|██████▋   | 2.71G/4.05G [00:32<00:16, 82.3MB/s]pytorch_model.bin:  67%|██████▋   | 2.72G/4.05G [00:32<00:16, 81.8MB/s]pytorch_model.bin:  67%|██████▋   | 2.73G/4.05G [00:33<00:16, 79.8MB/s]pytorch_model.bin:  68%|██████▊   | 2.74G/4.05G [00:33<00:15, 84.1MB/s]pytorch_model.bin:  68%|██████▊   | 2.75G/4.05G [00:33<00:16, 80.9MB/s]pytorch_model.bin:  68%|██████▊   | 2.76G/4.05G [00:33<00:15, 81.2MB/s]pytorch_model.bin:  68%|██████▊   | 2.77G/4.05G [00:33<00:18, 70.1MB/s]pytorch_model.bin:  69%|██████▊   | 2.78G/4.05G [00:33<00:18, 67.8MB/s]pytorch_model.bin:  69%|██████▉   | 2.80G/4.05G [00:34<00:15, 78.2MB/s]pytorch_model.bin:  69%|██████▉   | 2.81G/4.05G [00:34<00:16, 73.5MB/s]pytorch_model.bin:  70%|██████▉   | 2.82G/4.05G [00:34<00:16, 74.6MB/s]pytorch_model.bin:  70%|██████▉   | 2.83G/4.05G [00:34<00:15, 76.0MB/s]pytorch_model.bin:  70%|███████   | 2.84G/4.05G [00:34<00:15, 77.7MB/s]pytorch_model.bin:  70%|███████   | 2.85G/4.05G [00:34<00:15, 78.6MB/s]pytorch_model.bin:  71%|███████   | 2.86G/4.05G [00:34<00:15, 74.5MB/s]pytorch_model.bin:  71%|███████   | 2.87G/4.05G [00:34<00:14, 81.3MB/s]pytorch_model.bin:  71%|███████   | 2.88G/4.05G [00:35<00:15, 77.4MB/s]pytorch_model.bin:  72%|███████▏  | 2.89G/4.05G [00:35<00:15, 76.6MB/s]pytorch_model.bin:  72%|███████▏  | 2.90G/4.05G [00:35<00:15, 75.9MB/s]pytorch_model.bin:  72%|███████▏  | 2.92G/4.05G [00:35<00:14, 77.4MB/s]pytorch_model.bin:  72%|███████▏  | 2.93G/4.05G [00:35<00:15, 72.1MB/s]pytorch_model.bin:  73%|███████▎  | 2.94G/4.05G [00:35<00:13, 79.4MB/s]pytorch_model.bin:  73%|███████▎  | 2.95G/4.05G [00:35<00:13, 79.2MB/s]pytorch_model.bin:  73%|███████▎  | 2.97G/4.05G [00:36<00:12, 86.0MB/s]pytorch_model.bin:  74%|███████▎  | 2.98G/4.05G [00:36<00:13, 81.9MB/s]pytorch_model.bin:  74%|███████▍  | 2.99G/4.05G [00:36<00:12, 84.8MB/s]pytorch_model.bin:  74%|███████▍  | 3.00G/4.05G [00:36<00:12, 85.2MB/s]pytorch_model.bin:  74%|███████▍  | 3.01G/4.05G [00:36<00:12, 84.6MB/s]pytorch_model.bin:  75%|███████▍  | 3.02G/4.05G [00:36<00:12, 84.2MB/s]pytorch_model.bin:  75%|███████▍  | 3.03G/4.05G [00:36<00:12, 83.5MB/s]pytorch_model.bin:  75%|███████▌  | 3.04G/4.05G [00:37<00:12, 80.6MB/s]pytorch_model.bin:  75%|███████▌  | 3.05G/4.05G [00:37<00:12, 82.7MB/s]pytorch_model.bin:  76%|███████▌  | 3.06G/4.05G [00:37<00:11, 83.4MB/s]pytorch_model.bin:  76%|███████▌  | 3.07G/4.05G [00:37<00:11, 84.5MB/s]pytorch_model.bin:  76%|███████▌  | 3.08G/4.05G [00:37<00:11, 83.2MB/s]pytorch_model.bin:  76%|███████▋  | 3.09G/4.05G [00:37<00:11, 83.0MB/s]pytorch_model.bin:  77%|███████▋  | 3.10G/4.05G [00:37<00:11, 84.1MB/s]pytorch_model.bin:  77%|███████▋  | 3.11G/4.05G [00:37<00:11, 83.6MB/s]pytorch_model.bin:  77%|███████▋  | 3.12G/4.05G [00:38<00:11, 83.6MB/s]pytorch_model.bin:  77%|███████▋  | 3.14G/4.05G [00:38<00:10, 83.6MB/s]pytorch_model.bin:  78%|███████▊  | 3.15G/4.05G [00:38<00:10, 83.0MB/s]pytorch_model.bin:  78%|███████▊  | 3.16G/4.05G [00:38<00:10, 81.8MB/s]pytorch_model.bin:  78%|███████▊  | 3.17G/4.05G [00:38<00:10, 81.3MB/s]pytorch_model.bin:  79%|███████▊  | 3.18G/4.05G [00:38<00:10, 81.8MB/s]pytorch_model.bin:  79%|███████▉  | 3.19G/4.05G [00:38<00:10, 82.3MB/s]pytorch_model.bin:  79%|███████▉  | 3.20G/4.05G [00:38<00:10, 81.5MB/s]pytorch_model.bin:  79%|███████▉  | 3.21G/4.05G [00:39<00:10, 77.1MB/s]pytorch_model.bin:  80%|███████▉  | 3.22G/4.05G [00:39<00:10, 78.9MB/s]pytorch_model.bin:  80%|███████▉  | 3.23G/4.05G [00:39<00:10, 80.3MB/s]pytorch_model.bin:  80%|████████  | 3.24G/4.05G [00:39<00:10, 79.4MB/s]pytorch_model.bin:  80%|████████  | 3.25G/4.05G [00:39<00:09, 82.5MB/s]pytorch_model.bin:  81%|████████  | 3.26G/4.05G [00:39<00:09, 82.6MB/s]pytorch_model.bin:  81%|████████  | 3.27G/4.05G [00:39<00:09, 82.7MB/s]pytorch_model.bin:  81%|████████  | 3.28G/4.05G [00:39<00:09, 82.8MB/s]pytorch_model.bin:  81%|████████▏ | 3.29G/4.05G [00:40<00:09, 82.7MB/s]pytorch_model.bin:  82%|████████▏ | 3.30G/4.05G [00:40<00:08, 83.1MB/s]pytorch_model.bin:  82%|████████▏ | 3.31G/4.05G [00:40<00:09, 81.0MB/s]pytorch_model.bin:  82%|████████▏ | 3.32G/4.05G [00:40<00:08, 83.6MB/s]pytorch_model.bin:  82%|████████▏ | 3.33G/4.05G [00:40<00:08, 83.4MB/s]pytorch_model.bin:  83%|████████▎ | 3.34G/4.05G [00:40<00:08, 83.2MB/s]pytorch_model.bin:  83%|████████▎ | 3.36G/4.05G [00:40<00:08, 83.3MB/s]pytorch_model.bin:  83%|████████▎ | 3.37G/4.05G [00:41<00:08, 82.5MB/s]pytorch_model.bin:  83%|████████▎ | 3.38G/4.05G [00:41<00:08, 77.4MB/s]pytorch_model.bin:  84%|████████▍ | 3.40G/4.05G [00:41<00:07, 84.5MB/s]pytorch_model.bin:  84%|████████▍ | 3.41G/4.05G [00:41<00:07, 83.7MB/s]pytorch_model.bin:  84%|████████▍ | 3.42G/4.05G [00:41<00:07, 83.9MB/s]pytorch_model.bin:  85%|████████▍ | 3.43G/4.05G [00:41<00:07, 84.2MB/s]pytorch_model.bin:  85%|████████▍ | 3.44G/4.05G [00:41<00:07, 84.1MB/s]pytorch_model.bin:  85%|████████▌ | 3.45G/4.05G [00:42<00:07, 81.6MB/s]pytorch_model.bin:  85%|████████▌ | 3.46G/4.05G [00:42<00:07, 83.4MB/s]pytorch_model.bin:  86%|████████▌ | 3.47G/4.05G [00:42<00:07, 78.1MB/s]pytorch_model.bin:  86%|████████▋ | 3.49G/4.05G [00:42<00:06, 83.2MB/s]pytorch_model.bin:  87%|████████▋ | 3.50G/4.05G [00:42<00:06, 81.6MB/s]pytorch_model.bin:  87%|████████▋ | 3.51G/4.05G [00:42<00:08, 64.2MB/s]pytorch_model.bin:  87%|████████▋ | 3.53G/4.05G [00:43<00:06, 79.9MB/s]pytorch_model.bin:  88%|████████▊ | 3.54G/4.05G [00:43<00:06, 79.9MB/s]pytorch_model.bin:  88%|████████▊ | 3.55G/4.05G [00:43<00:06, 72.4MB/s]pytorch_model.bin:  88%|████████▊ | 3.57G/4.05G [00:43<00:07, 67.6MB/s]pytorch_model.bin:  88%|████████▊ | 3.58G/4.05G [00:43<00:06, 69.6MB/s]pytorch_model.bin:  89%|████████▊ | 3.59G/4.05G [00:43<00:07, 65.3MB/s]pytorch_model.bin:  89%|████████▉ | 3.60G/4.05G [00:44<00:07, 62.5MB/s]pytorch_model.bin:  89%|████████▉ | 3.61G/4.05G [00:44<00:07, 61.5MB/s]pytorch_model.bin:  89%|████████▉ | 3.62G/4.05G [00:44<00:06, 63.1MB/s]pytorch_model.bin:  90%|████████▉ | 3.63G/4.05G [00:44<00:06, 62.1MB/s]pytorch_model.bin:  90%|████████▉ | 3.64G/4.05G [00:44<00:06, 64.5MB/s]pytorch_model.bin:  90%|█████████ | 3.65G/4.05G [00:44<00:06, 62.4MB/s]pytorch_model.bin:  90%|█████████ | 3.66G/4.05G [00:45<00:06, 61.3MB/s]pytorch_model.bin:  91%|█████████ | 3.67G/4.05G [00:45<00:05, 64.0MB/s]pytorch_model.bin:  91%|█████████ | 3.68G/4.05G [00:45<00:05, 63.8MB/s]pytorch_model.bin:  91%|█████████ | 3.69G/4.05G [00:45<00:05, 62.8MB/s]pytorch_model.bin:  91%|█████████▏| 3.70G/4.05G [00:45<00:05, 65.4MB/s]pytorch_model.bin:  92%|█████████▏| 3.71G/4.05G [00:45<00:05, 64.6MB/s]pytorch_model.bin:  92%|█████████▏| 3.72G/4.05G [00:46<00:04, 66.1MB/s]pytorch_model.bin:  92%|█████████▏| 3.73G/4.05G [00:46<00:04, 66.3MB/s]pytorch_model.bin:  92%|█████████▏| 3.74G/4.05G [00:46<00:05, 58.5MB/s]pytorch_model.bin:  93%|█████████▎| 3.75G/4.05G [00:46<00:04, 64.5MB/s]pytorch_model.bin:  93%|█████████▎| 3.76G/4.05G [00:46<00:04, 70.3MB/s]pytorch_model.bin:  93%|█████████▎| 3.77G/4.05G [00:46<00:03, 69.4MB/s]pytorch_model.bin:  94%|█████████▎| 3.79G/4.05G [00:47<00:03, 65.7MB/s]pytorch_model.bin:  94%|█████████▍| 3.80G/4.05G [00:47<00:03, 70.3MB/s]pytorch_model.bin:  94%|█████████▍| 3.81G/4.05G [00:47<00:03, 69.1MB/s]pytorch_model.bin:  94%|█████████▍| 3.82G/4.05G [00:47<00:03, 69.5MB/s]pytorch_model.bin:  95%|█████████▍| 3.83G/4.05G [00:47<00:03, 67.9MB/s]pytorch_model.bin:  95%|█████████▍| 3.84G/4.05G [00:47<00:03, 68.9MB/s]pytorch_model.bin:  95%|█████████▌| 3.85G/4.05G [00:47<00:02, 67.7MB/s]pytorch_model.bin:  95%|█████████▌| 3.86G/4.05G [00:48<00:02, 69.6MB/s]pytorch_model.bin:  96%|█████████▌| 3.87G/4.05G [00:48<00:02, 70.2MB/s]pytorch_model.bin:  96%|█████████▌| 3.88G/4.05G [00:48<00:02, 68.9MB/s]pytorch_model.bin:  96%|█████████▌| 3.89G/4.05G [00:48<00:02, 69.4MB/s]pytorch_model.bin:  96%|█████████▋| 3.90G/4.05G [00:48<00:02, 68.5MB/s]pytorch_model.bin:  97%|█████████▋| 3.91G/4.05G [00:48<00:01, 70.1MB/s]pytorch_model.bin:  97%|█████████▋| 3.92G/4.05G [00:48<00:01, 70.3MB/s]pytorch_model.bin:  97%|█████████▋| 3.93G/4.05G [00:49<00:01, 69.5MB/s]pytorch_model.bin:  97%|█████████▋| 3.94G/4.05G [00:49<00:01, 70.1MB/s]pytorch_model.bin:  98%|█████████▊| 3.95G/4.05G [00:49<00:01, 68.9MB/s]pytorch_model.bin:  98%|█████████▊| 3.96G/4.05G [00:49<00:01, 70.5MB/s]pytorch_model.bin:  98%|█████████▊| 3.97G/4.05G [00:49<00:01, 71.2MB/s]pytorch_model.bin:  98%|█████████▊| 3.98G/4.05G [00:49<00:00, 69.6MB/s]pytorch_model.bin:  99%|█████████▊| 4.00G/4.05G [00:50<00:00, 70.2MB/s]pytorch_model.bin:  99%|█████████▉| 4.01G/4.05G [00:50<00:00, 62.1MB/s]pytorch_model.bin:  99%|█████████▉| 4.02G/4.05G [00:50<00:00, 67.0MB/s]pytorch_model.bin:  99%|█████████▉| 4.03G/4.05G [00:50<00:00, 70.2MB/s]pytorch_model.bin: 100%|█████████▉| 4.04G/4.05G [00:50<00:00, 70.7MB/s]pytorch_model.bin: 100%|██████████| 4.05G/4.05G [00:50<00:00, 68.1MB/s]pytorch_model.bin: 100%|██████████| 4.05G/4.05G [00:50<00:00, 79.6MB/s]
generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]generation_config.json: 100%|██████████| 111/111 [00:00<00:00, 631kB/s]
tokenizer_config.json:   0%|          | 0.00/4.82k [00:00<?, ?B/s]tokenizer_config.json: 100%|██████████| 4.82k/4.82k [00:00<00:00, 30.9MB/s]
tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]tokenizer.json: 100%|██████████| 2.11M/2.11M [00:00<00:00, 14.8MB/s]tokenizer.json: 100%|██████████| 2.11M/2.11M [00:00<00:00, 14.7MB/s]
special_tokens_map.json:   0%|          | 0.00/153 [00:00<?, ?B/s]special_tokens_map.json: 100%|██████████| 153/153 [00:00<00:00, 1.07MB/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-01-16:16:35:39,760 INFO     [huggingface.py:298] Using 8 devices with data parallelism
2024-01-16:16:35:46,670 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:16:35:46,670 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:16:35:46,765 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:16:35:46,765 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:16:35:46,839 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:16:35:46,839 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:16:35:46,869 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:16:35:46,869 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:16:35:46,904 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:16:35:46,904 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:16:35:47,031 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:16:35:47,031 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:16:35:47,045 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:16:35:47,045 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:16:35:47,563 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:16:35:47,563 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:16:35:55,662 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:16:35:55,662 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:16:35:55,856 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:16:35:55,856 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:16:35:56,023 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:16:35:56,023 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:16:35:56,080 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:16:35:56,080 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:16:35:56,088 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:16:35:56,088 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:16:35:56,312 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:16:35:56,312 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:16:35:56,545 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:16:35:56,545 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:16:35:56,951 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:16:35:56,951 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:16:36:07,216 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:16:36:07,216 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:16:36:07,216 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:16:36:07,216 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:16:36:07,216 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:16:36:07,216 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:16:36:07,325 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:16:36:07,325 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:16:36:07,325 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:16:36:07,325 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:16:36:07,325 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:16:36:07,325 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:16:36:07,484 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:16:36:07,484 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:16:36:07,484 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:16:36:07,484 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:16:36:07,484 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:16:36:07,484 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:16:36:07,754 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:16:36:07,755 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:16:36:07,755 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:16:36:07,755 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:16:36:07,755 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:16:36:07,755 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:16:36:08,134 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:16:36:08,134 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:16:36:08,134 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:16:36:08,134 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:16:36:08,134 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:16:36:08,134 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:16:36:08,221 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:16:36:08,221 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:16:36:08,221 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:16:36:08,221 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:16:36:08,221 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:16:36:08,221 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:16:36:08,376 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:16:36:08,376 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:16:36:08,376 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:16:36:08,376 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:16:36:08,376 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:16:36:08,376 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:16:36:08,452 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:16:36:08,452 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:16:36:08,452 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:16:36:08,452 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:16:36:08,452 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:16:36:08,452 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:16:36:11,850 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:16:36:11,850 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:16:36:11,850 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:16:36:11,851 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:16:36:11,851 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:16:36:11,851 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:16:36:11,851 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:16:36:11,851 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:16:36:11,851 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:16:36:11,851 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:16:36:11,851 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:16:36:12,092 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:16:36:12,092 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:16:36:12,092 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:16:36:12,092 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:16:36:12,092 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:16:36:12,092 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:16:36:12,092 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:16:36:12,092 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:16:36:12,092 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:16:36:12,092 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:16:36:12,092 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:16:36:12,311 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:16:36:12,311 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:16:36:12,311 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:16:36:12,311 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:16:36:12,311 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:16:36:12,311 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:16:36:12,311 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:16:36:12,311 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:16:36:12,311 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:16:36:12,311 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:16:36:12,312 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:16:36:12,405 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:16:36:12,405 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:16:36:12,405 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:16:36:12,405 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:16:36:12,405 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:16:36:12,405 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:16:36:12,405 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:16:36:12,405 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:16:36:12,405 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:16:36:12,405 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:16:36:12,405 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:16:36:12,953 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:16:36:12,953 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:16:36:12,953 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:16:36:12,953 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:16:36:12,953 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:16:36:12,953 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:16:36:12,953 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:16:36:12,953 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:16:36:12,953 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:16:36:12,953 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:16:36:12,954 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:16:36:13,057 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:16:36:13,057 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:16:36:13,057 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:16:36:13,057 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:16:36:13,057 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:16:36:13,057 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:16:36:13,057 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:16:36:13,057 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:16:36:13,057 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:16:36:13,057 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:16:36:13,057 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:16:36:13,164 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:16:36:13,164 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:16:36:13,164 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:16:36:13,164 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:16:36:13,164 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:16:36:13,164 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:16:36:13,164 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:16:36:13,164 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:16:36:13,164 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:16:36:13,164 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:16:36:13,164 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:16:36:13,221 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:16:36:13,221 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:16:36:13,221 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:16:36:13,221 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:16:36:13,221 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:16:36:13,221 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:16:36:13,221 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:16:36:13,221 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:16:36:13,221 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:16:36:13,221 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:16:36:13,221 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:16:36:24,888 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:16:36:24,888 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:16:36:24,888 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:16:36:24,888 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:16:36:24,888 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:16:36:24,889 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:16:36:24,889 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:16:36:24,889 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:16:36:25,308 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:16:36:25,308 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:16:36:25,308 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:16:36:25,308 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:16:36:25,308 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:16:36:25,308 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:16:36:25,308 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:16:36:25,308 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:16:36:25,634 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:16:36:25,634 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:16:36:25,634 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:16:36:25,634 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:16:36:25,635 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:16:36:25,635 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:16:36:25,635 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:16:36:25,635 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:16:36:27,091 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:16:36:27,091 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:16:36:27,091 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:16:36:27,091 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:16:36:27,091 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:16:36:27,091 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:16:36:27,091 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:16:36:27,091 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:16:36:28,218 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:16:36:28,218 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:16:36:28,218 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:16:36:28,218 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:16:36:28,218 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:16:36:28,218 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:16:36:28,218 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:16:36:28,218 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:16:36:28,273 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:16:36:28,273 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:16:36:28,273 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:16:36:28,273 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:16:36:28,273 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:16:36:28,273 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:16:36:28,273 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:16:36:28,274 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:16:36:28,540 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:16:36:28,540 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:16:36:28,540 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:16:36:28,540 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:16:36:28,540 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:16:36:28,540 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:16:36:28,540 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:16:36:28,540 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:16:36:28,745 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:16:36:28,745 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:16:36:28,745 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:16:36:28,745 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:16:36:28,745 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:16:36:28,745 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:16:36:28,745 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:16:36:28,745 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:16:36:28,765 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:16:36:28,765 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:16:36:28,765 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:16:36:28,765 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:16:36:28,765 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:16:36:28,765 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:16:36:28,765 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:16:36:28,765 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:16:36:28,803 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:16:36:28,803 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:16:36:28,803 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:16:36:28,803 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:16:36:28,803 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:16:36:28,803 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:16:36:28,803 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:16:36:28,803 INFO     [evaluator.py:314] Running loglikelihood requests
  0%|          | 0/9788 [00:00<?, ?it/s]  0%|          | 1/9788 [00:01<4:38:31,  1.71s/it]  0%|          | 33/9788 [00:01<06:46, 23.97it/s]   1%|          | 65/9788 [00:02<03:14, 50.01it/s]  1%|          | 97/9788 [00:02<02:03, 78.54it/s]  1%|▏         | 129/9788 [00:02<01:28, 109.01it/s]  2%|▏         | 161/9788 [00:02<01:08, 140.81it/s]  2%|▏         | 193/9788 [00:02<00:55, 173.57it/s]  2%|▏         | 225/9788 [00:02<00:46, 203.86it/s]  3%|▎         | 270/9788 [00:02<00:36, 260.23it/s]  3%|▎         | 305/9788 [00:02<00:36, 256.59it/s]  4%|▎         | 353/9788 [00:02<00:33, 285.59it/s]  4%|▍         | 401/9788 [00:03<00:30, 310.09it/s]  5%|▍         | 449/9788 [00:03<00:28, 328.65it/s]  5%|▌         | 497/9788 [00:03<00:26, 344.29it/s]  6%|▌         | 545/9788 [00:03<00:25, 355.50it/s]  6%|▌         | 593/9788 [00:03<00:25, 364.96it/s]  7%|▋         | 641/9788 [00:03<00:24, 375.49it/s]  7%|▋         | 689/9788 [00:03<00:23, 384.20it/s]  8%|▊         | 737/9788 [00:03<00:23, 391.10it/s]  8%|▊         | 785/9788 [00:04<00:22, 396.26it/s]  9%|▊         | 833/9788 [00:04<00:22, 400.02it/s]  9%|▉         | 881/9788 [00:04<00:22, 402.38it/s]  9%|▉         | 929/9788 [00:04<00:21, 403.34it/s] 10%|▉         | 977/9788 [00:04<00:21, 404.88it/s] 10%|█         | 1025/9788 [00:04<00:21, 405.34it/s] 11%|█         | 1073/9788 [00:04<00:21, 407.61it/s] 11%|█▏        | 1121/9788 [00:04<00:21, 407.97it/s] 12%|█▏        | 1169/9788 [00:04<00:21, 408.51it/s] 12%|█▏        | 1217/9788 [00:05<00:20, 409.86it/s] 13%|█▎        | 1265/9788 [00:05<00:20, 409.72it/s] 13%|█▎        | 1313/9788 [00:05<00:20, 412.40it/s] 14%|█▍        | 1361/9788 [00:05<00:20, 413.47it/s] 14%|█▍        | 1409/9788 [00:05<00:20, 413.28it/s] 15%|█▍        | 1457/9788 [00:05<00:20, 414.00it/s] 15%|█▌        | 1505/9788 [00:05<00:19, 415.10it/s] 16%|█▌        | 1553/9788 [00:05<00:19, 414.59it/s] 16%|█▋        | 1601/9788 [00:06<00:19, 414.12it/s] 17%|█▋        | 1649/9788 [00:06<00:19, 415.70it/s] 17%|█▋        | 1697/9788 [00:06<00:19, 416.42it/s] 18%|█▊        | 1745/9788 [00:06<00:19, 415.77it/s] 18%|█▊        | 1793/9788 [00:06<00:19, 416.24it/s] 19%|█▉        | 1841/9788 [00:06<00:19, 417.47it/s] 19%|█▉        | 1889/9788 [00:06<00:18, 417.51it/s] 20%|█▉        | 1937/9788 [00:06<00:18, 422.03it/s] 20%|██        | 1985/9788 [00:06<00:17, 436.46it/s] 21%|██        | 2033/9788 [00:07<00:17, 446.74it/s] 21%|██▏       | 2081/9788 [00:07<00:17, 452.42it/s] 22%|██▏       | 2129/9788 [00:07<00:16, 456.31it/s] 22%|██▏       | 2177/9788 [00:07<00:16, 459.27it/s] 23%|██▎       | 2225/9788 [00:07<00:16, 462.26it/s] 23%|██▎       | 2273/9788 [00:07<00:16, 463.51it/s] 24%|██▎       | 2321/9788 [00:07<00:16, 464.07it/s] 24%|██▍       | 2369/9788 [00:07<00:15, 467.13it/s] 25%|██▍       | 2417/9788 [00:07<00:15, 468.04it/s] 25%|██▌       | 2465/9788 [00:07<00:15, 468.60it/s] 26%|██▌       | 2513/9788 [00:08<00:15, 469.06it/s] 26%|██▌       | 2561/9788 [00:08<00:15, 471.11it/s] 27%|██▋       | 2609/9788 [00:08<00:15, 472.39it/s] 27%|██▋       | 2657/9788 [00:08<00:15, 471.65it/s] 28%|██▊       | 2705/9788 [00:08<00:15, 471.42it/s] 28%|██▊       | 2757/9788 [00:08<00:14, 485.79it/s] 29%|██▊       | 2811/9788 [00:08<00:13, 501.78it/s] 29%|██▉       | 2862/9788 [00:08<00:13, 502.37it/s] 30%|██▉       | 2913/9788 [00:08<00:14, 460.54it/s] 30%|███       | 2965/9788 [00:09<00:14, 476.97it/s] 31%|███       | 3014/9788 [00:09<00:14, 477.99it/s] 31%|███▏      | 3063/9788 [00:09<00:13, 481.09it/s] 32%|███▏      | 3112/9788 [00:09<00:13, 483.05it/s] 32%|███▏      | 3167/9788 [00:09<00:13, 502.56it/s] 33%|███▎      | 3218/9788 [00:09<00:14, 464.03it/s] 33%|███▎      | 3267/9788 [00:09<00:13, 471.21it/s] 34%|███▍      | 3316/9788 [00:09<00:13, 476.55it/s] 34%|███▍      | 3371/9788 [00:09<00:12, 497.75it/s] 35%|███▍      | 3425/9788 [00:09<00:13, 467.77it/s] 36%|███▌      | 3475/9788 [00:10<00:13, 476.67it/s] 36%|███▌      | 3524/9788 [00:10<00:13, 480.27it/s] 37%|███▋      | 3585/9788 [00:10<00:13, 476.37it/s] 37%|███▋      | 3637/9788 [00:10<00:12, 488.16it/s] 38%|███▊      | 3688/9788 [00:10<00:12, 494.19it/s] 38%|███▊      | 3745/9788 [00:10<00:12, 474.60it/s] 39%|███▉      | 3797/9788 [00:10<00:12, 486.97it/s] 39%|███▉      | 3848/9788 [00:10<00:12, 493.33it/s] 40%|███▉      | 3902/9788 [00:10<00:11, 506.65it/s] 40%|████      | 3953/9788 [00:11<00:12, 468.59it/s] 41%|████      | 4008/9788 [00:11<00:11, 490.95it/s] 42%|████▏     | 4064/9788 [00:11<00:11, 510.44it/s] 42%|████▏     | 4116/9788 [00:11<00:11, 474.10it/s] 43%|████▎     | 4173/9788 [00:11<00:11, 500.47it/s] 43%|████▎     | 4225/9788 [00:11<00:11, 466.11it/s] 44%|████▍     | 4289/9788 [00:11<00:11, 477.15it/s] 44%|████▍     | 4353/9788 [00:11<00:11, 482.56it/s] 45%|████▌     | 4417/9788 [00:12<00:10, 488.34it/s] 46%|████▌     | 4481/9788 [00:12<00:10, 493.89it/s] 46%|████▋     | 4545/9788 [00:12<00:10, 496.43it/s] 47%|████▋     | 4609/9788 [00:12<00:10, 499.11it/s] 48%|████▊     | 4673/9788 [00:12<00:10, 500.64it/s] 48%|████▊     | 4737/9788 [00:12<00:10, 501.70it/s] 49%|████▉     | 4801/9788 [00:12<00:09, 503.30it/s] 50%|████▉     | 4865/9788 [00:12<00:09, 506.64it/s] 50%|█████     | 4929/9788 [00:13<00:09, 517.26it/s] 51%|█████     | 4993/9788 [00:13<00:09, 523.61it/s] 52%|█████▏    | 5057/9788 [00:13<00:08, 529.10it/s] 52%|█████▏    | 5121/9788 [00:13<00:08, 533.31it/s] 53%|█████▎    | 5185/9788 [00:13<00:08, 536.37it/s] 54%|█████▎    | 5249/9788 [00:13<00:08, 538.79it/s] 54%|█████▍    | 5313/9788 [00:13<00:08, 537.54it/s] 55%|█████▍    | 5377/9788 [00:13<00:08, 542.00it/s] 56%|█████▌    | 5441/9788 [00:13<00:07, 544.85it/s] 56%|█████▌    | 5505/9788 [00:14<00:07, 547.15it/s] 57%|█████▋    | 5569/9788 [00:14<00:07, 548.57it/s] 58%|█████▊    | 5633/9788 [00:14<00:07, 550.63it/s] 58%|█████▊    | 5697/9788 [00:14<00:07, 553.55it/s] 59%|█████▉    | 5761/9788 [00:14<00:07, 556.10it/s] 60%|█████▉    | 5825/9788 [00:14<00:07, 557.29it/s] 60%|██████    | 5889/9788 [00:14<00:06, 559.14it/s] 61%|██████    | 5953/9788 [00:14<00:06, 559.97it/s] 61%|██████▏   | 6017/9788 [00:14<00:06, 560.70it/s] 62%|██████▏   | 6081/9788 [00:15<00:06, 568.12it/s] 63%|██████▎   | 6145/9788 [00:15<00:06, 575.32it/s] 63%|██████▎   | 6209/9788 [00:15<00:06, 579.47it/s] 64%|██████▍   | 6273/9788 [00:15<00:06, 582.56it/s] 65%|██████▍   | 6337/9788 [00:15<00:05, 585.90it/s] 65%|██████▌   | 6401/9788 [00:15<00:05, 589.20it/s] 66%|██████▌   | 6465/9788 [00:15<00:05, 590.77it/s] 67%|██████▋   | 6529/9788 [00:15<00:05, 591.02it/s] 67%|██████▋   | 6593/9788 [00:15<00:05, 591.65it/s] 68%|██████▊   | 6657/9788 [00:16<00:05, 592.41it/s] 69%|██████▊   | 6721/9788 [00:16<00:05, 592.25it/s] 69%|██████▉   | 6785/9788 [00:16<00:05, 592.70it/s] 70%|██████▉   | 6849/9788 [00:16<00:04, 592.88it/s] 71%|███████   | 6913/9788 [00:16<00:04, 592.55it/s] 71%|███████▏  | 6977/9788 [00:16<00:04, 593.18it/s] 72%|███████▏  | 7041/9788 [00:16<00:04, 593.24it/s] 73%|███████▎  | 7105/9788 [00:16<00:04, 593.11it/s] 73%|███████▎  | 7169/9788 [00:16<00:04, 592.25it/s] 74%|███████▍  | 7233/9788 [00:17<00:04, 594.14it/s] 75%|███████▍  | 7297/9788 [00:17<00:04, 593.84it/s] 75%|███████▌  | 7361/9788 [00:17<00:04, 593.44it/s] 76%|███████▌  | 7425/9788 [00:17<00:03, 593.70it/s] 77%|███████▋  | 7489/9788 [00:17<00:03, 594.44it/s] 77%|███████▋  | 7553/9788 [00:17<00:03, 595.63it/s] 78%|███████▊  | 7617/9788 [00:17<00:03, 596.78it/s] 78%|███████▊  | 7681/9788 [00:17<00:03, 597.92it/s] 79%|███████▉  | 7745/9788 [00:17<00:03, 598.27it/s] 80%|███████▉  | 7809/9788 [00:17<00:03, 599.68it/s] 80%|████████  | 7873/9788 [00:18<00:03, 600.53it/s] 81%|████████  | 7937/9788 [00:18<00:03, 601.82it/s] 82%|████████▏ | 8001/9788 [00:18<00:02, 601.56it/s] 82%|████████▏ | 8065/9788 [00:18<00:02, 601.27it/s] 83%|████████▎ | 8129/9788 [00:18<00:02, 602.09it/s] 84%|████████▎ | 8193/9788 [00:18<00:02, 602.20it/s] 84%|████████▍ | 8257/9788 [00:18<00:02, 602.13it/s] 85%|████████▌ | 8321/9788 [00:18<00:02, 604.38it/s] 86%|████████▌ | 8385/9788 [00:18<00:02, 604.67it/s] 86%|████████▋ | 8449/9788 [00:19<00:02, 605.89it/s] 87%|████████▋ | 8513/9788 [00:19<00:02, 605.99it/s] 88%|████████▊ | 8577/9788 [00:19<00:01, 607.20it/s] 88%|████████▊ | 8641/9788 [00:19<00:01, 606.68it/s] 89%|████████▉ | 8705/9788 [00:19<00:01, 607.34it/s] 90%|████████▉ | 8769/9788 [00:19<00:01, 607.46it/s] 90%|█████████ | 8833/9788 [00:19<00:01, 607.47it/s] 91%|█████████ | 8897/9788 [00:19<00:01, 608.51it/s] 92%|█████████▏| 8961/9788 [00:19<00:01, 608.32it/s] 92%|█████████▏| 9025/9788 [00:20<00:01, 609.42it/s] 93%|█████████▎| 9089/9788 [00:20<00:01, 609.39it/s] 94%|█████████▎| 9153/9788 [00:20<00:01, 609.89it/s] 94%|█████████▍| 9217/9788 [00:20<00:00, 609.14it/s] 95%|█████████▍| 9281/9788 [00:20<00:00, 609.26it/s] 95%|█████████▌| 9345/9788 [00:20<00:00, 603.52it/s] 96%|█████████▌| 9409/9788 [00:20<00:00, 604.95it/s] 97%|█████████▋| 9473/9788 [00:20<00:00, 606.45it/s] 97%|█████████▋| 9537/9788 [00:20<00:00, 607.02it/s] 98%|█████████▊| 9601/9788 [00:20<00:00, 606.41it/s] 99%|█████████▊| 9665/9788 [00:21<00:00, 605.38it/s] 99%|█████████▉| 9729/9788 [00:21<00:00, 607.73it/s]100%|██████████| 9788/9788 [00:21<00:00, 460.80it/s]
2024-01-16:16:36:54,008 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:16:36:54,008 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:16:36:54,008 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:16:36:54,008 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:16:36:54,008 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:16:36:54,008 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:16:36:54,008 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:16:36:54,008 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
  0%|          | 0/8 [00:00<?, ?it/s] 12%|█▎        | 1/8 [00:00<00:01,  6.82it/s] 25%|██▌       | 2/8 [00:00<00:01,  3.92it/s] 38%|███▊      | 3/8 [00:00<00:01,  3.94it/s] 50%|█████     | 4/8 [00:00<00:00,  4.13it/s] 62%|██████▎   | 5/8 [00:01<00:00,  3.92it/s] 75%|███████▌  | 6/8 [00:01<00:00,  4.04it/s]100%|██████████| 8/8 [00:01<00:00,  5.54it/s]100%|██████████| 8/8 [00:01<00:00,  4.74it/s]
bootstrapping for stddev: perplexity
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:01<01:41,  1.03s/it]  4%|▍         | 4/100 [00:01<00:25,  3.84it/s] 97%|█████████▋| 97/100 [00:01<00:00, 109.26it/s]100%|██████████| 100/100 [00:01<00:00, 66.86it/s]
hf (pretrained=lomahony/pythia-1b-helpful-dpo), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 16
|    Tasks     |Version|Filter|n-shot|    Metric     | Value |   |Stderr|
|--------------|------:|------|-----:|---------------|------:|---|------|
|arc_challenge |      1|none  |     0|acc            | 0.2602|±  |0.0128|
|              |       |none  |     0|acc_norm       | 0.2867|±  |0.0132|
|arc_easy      |      1|none  |     0|acc            | 0.5859|±  |0.0101|
|              |       |none  |     0|acc_norm       | 0.5008|±  |0.0103|
|boolq         |      2|none  |     0|acc            | 0.6205|±  |0.0085|
|hellaswag     |      1|none  |     0|acc            | 0.3895|±  |0.0049|
|              |       |none  |     0|acc_norm       | 0.4872|±  |0.0050|
|lambada_openai|      1|none  |     0|perplexity     | 6.9417|±  |0.2019|
|              |       |none  |     0|acc            | 0.5550|±  |0.0069|
|openbookqa    |      1|none  |     0|acc            | 0.2140|±  |0.0184|
|              |       |none  |     0|acc_norm       | 0.3220|±  |0.0209|
|piqa          |      1|none  |     0|acc            | 0.7193|±  |0.0105|
|              |       |none  |     0|acc_norm       | 0.7008|±  |0.0107|
|sciq          |      1|none  |     0|acc            | 0.8450|±  |0.0115|
|              |       |none  |     0|acc_norm       | 0.7600|±  |0.0135|
|wikitext      |      2|none  |     0|word_perplexity|17.2316|±  |N/A   |
|              |       |none  |     0|byte_perplexity| 1.7029|±  |N/A   |
|              |       |none  |     0|bits_per_byte  | 0.7680|±  |N/A   |
|winogrande    |      1|none  |     0|acc            | 0.5367|±  |0.0140|

