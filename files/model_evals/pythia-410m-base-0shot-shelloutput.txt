The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `8`
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-01-16:01:15:18,053 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:01:15:18,053 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:01:15:18,053 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:01:15:18,054 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:01:15:18,054 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:01:15:18,054 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:01:15:18,055 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:01:15:18,055 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:01:15:18,056 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:01:15:18,056 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:01:15:18,172 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:01:15:18,172 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:01:15:18,190 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:01:15:18,191 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:01:15:18,192 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:01:15:18,192 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:01:15:18,625 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:01:15:18,626 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:01:15:18,626 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:01:15:18,627 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:01:15:18,629 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:01:15:18,692 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:01:15:18,720 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:01:15:18,748 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:01:15:23,320 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:01:15:23,320 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:01:15:23,321 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:01:15:23,325 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:01:15:23,350 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:01:15:23,392 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:01:15:23,393 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:01:15:23,476 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:01:15:30,295 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:15:30,314 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:15:30,429 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:15:30,430 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:15:30,561 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:15:30,664 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:01:15:31,362 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:01:15:31,499 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:01:16:23,955 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:16:23,962 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:01:16:23,966 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:16:23,972 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:01:16:24,276 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:16:24,280 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:01:16:24,586 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:16:24,589 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:01:16:24,654 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:16:24,658 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:01:16:25,379 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:16:25,383 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:01:16:25,596 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:16:25,601 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:01:16:26,334 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:16:26,338 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-01-16:01:16:33,535 INFO     [huggingface.py:298] Using 8 devices with data parallelism
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-01-16:01:16:40,197 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:01:16:40,197 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:01:16:40,446 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:01:16:40,446 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:01:16:40,563 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:01:16:40,563 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:01:16:40,647 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:01:16:40,648 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:01:16:40,688 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:01:16:40,688 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:01:16:40,808 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:01:16:40,808 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:01:16:40,819 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:01:16:40,819 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:01:16:40,934 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:01:16:40,934 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:01:16:49,290 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:16:49,290 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:16:49,444 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:16:49,444 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:16:49,687 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:16:49,688 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:16:49,759 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:16:49,759 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:16:49,948 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:16:49,948 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:16:50,020 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:16:50,021 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:16:50,109 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:16:50,109 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:16:50,503 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:16:50,503 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:17:00,140 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:17:00,141 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:17:00,141 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:17:00,141 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:17:00,141 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:01:17:00,141 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:17:00,335 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:17:00,335 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:17:00,335 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:17:00,335 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:17:00,336 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:01:17:00,336 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:17:00,563 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:17:00,563 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:17:00,563 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:17:00,563 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:17:00,563 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:01:17:00,563 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:17:01,022 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:17:01,023 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:17:01,023 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:17:01,023 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:17:01,023 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:01:17:01,023 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:17:01,312 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:17:01,312 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:17:01,312 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:17:01,312 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:17:01,312 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:01:17:01,312 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:17:01,330 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:17:01,330 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:17:01,330 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:17:01,330 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:17:01,330 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:01:17:01,330 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:17:01,622 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:17:01,622 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:17:01,622 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:17:01,622 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:17:01,622 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:01:17:01,622 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:17:01,675 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:17:01,675 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:17:01,675 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:17:01,675 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:17:01,675 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:01:17:01,675 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:17:04,872 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:01:17:04,872 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:01:17:04,872 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:01:17:04,872 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:01:17:04,872 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:01:17:04,872 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:01:17:04,872 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:01:17:04,872 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:01:17:04,872 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:01:17:04,872 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:01:17:04,872 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:17:05,003 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:01:17:05,004 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:01:17:05,004 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:01:17:05,004 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:01:17:05,004 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:01:17:05,004 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:01:17:05,004 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:01:17:05,004 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:01:17:05,004 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:01:17:05,004 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:01:17:05,005 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:17:05,294 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:01:17:05,294 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:01:17:05,294 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:01:17:05,294 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:01:17:05,294 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:01:17:05,294 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:01:17:05,294 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:01:17:05,294 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:01:17:05,294 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:01:17:05,294 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:01:17:05,294 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:17:05,893 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:01:17:05,893 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:01:17:05,894 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:01:17:05,894 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:01:17:05,894 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:01:17:05,894 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:01:17:05,894 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:01:17:05,894 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:01:17:05,894 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:01:17:05,894 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:01:17:05,894 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:17:05,967 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:01:17:05,967 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:01:17:05,967 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:01:17:05,967 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:01:17:05,967 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:01:17:05,967 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:01:17:05,967 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:01:17:05,967 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:01:17:05,967 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:01:17:05,967 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:01:17:05,967 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:17:05,974 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:01:17:05,974 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:01:17:05,974 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:01:17:05,974 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:01:17:05,974 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:01:17:05,974 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:01:17:05,974 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:01:17:05,974 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:01:17:05,974 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:01:17:05,974 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:01:17:05,975 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:17:06,293 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:01:17:06,293 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:01:17:06,293 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:01:17:06,293 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:01:17:06,293 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:01:17:06,293 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:01:17:06,293 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:01:17:06,294 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:01:17:06,294 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:01:17:06,294 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:01:17:06,294 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:17:06,360 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:01:17:06,361 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:01:17:06,361 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:01:17:06,361 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:01:17:06,361 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:01:17:06,361 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:01:17:06,361 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:01:17:06,361 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:01:17:06,361 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:01:17:06,361 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:01:17:06,361 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:17:18,421 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:17:18,421 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:17:18,421 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:17:18,421 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:17:18,422 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:17:18,422 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:17:18,423 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:17:18,423 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:17:18,843 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:17:18,843 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:17:18,843 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:17:18,843 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:17:18,843 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:17:18,843 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:17:18,843 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:17:18,843 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:17:19,168 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:17:19,168 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:17:19,168 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:17:19,168 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:17:19,168 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:17:19,168 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:17:19,169 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:17:19,169 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:17:20,612 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:17:20,612 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:17:20,612 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:17:20,612 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:17:20,612 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:17:20,612 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:17:20,612 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:17:20,612 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:17:21,726 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:17:21,726 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:17:21,726 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:17:21,726 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:17:21,726 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:17:21,726 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:17:21,726 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:17:21,726 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:17:21,781 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:17:21,781 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:17:21,781 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:17:21,781 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:17:21,781 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:17:21,781 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:17:21,781 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:17:21,781 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:17:22,046 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:17:22,046 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:17:22,046 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:17:22,046 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:17:22,046 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:17:22,046 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:17:22,046 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:17:22,046 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:17:22,236 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:17:22,236 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:17:22,236 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:17:22,236 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:17:22,236 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:17:22,236 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:17:22,236 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:17:22,236 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:17:22,256 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:17:22,256 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:17:22,256 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:17:22,256 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:17:22,256 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:17:22,256 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:17:22,256 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:17:22,256 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:17:22,294 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:01:17:22,294 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:01:17:22,294 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:01:17:22,294 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:01:17:22,294 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:01:17:22,294 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:01:17:22,294 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:01:17:22,295 INFO     [evaluator.py:314] Running loglikelihood requests
  0%|          | 0/9788 [00:00<?, ?it/s]  0%|          | 1/9788 [00:01<4:41:27,  1.73s/it]  0%|          | 33/9788 [00:01<06:40, 24.36it/s]   1%|          | 65/9788 [00:01<03:06, 52.16it/s]  1%|          | 97/9788 [00:02<01:55, 84.04it/s]  1%|         | 145/9788 [00:02<01:11, 135.03it/s]  2%|         | 193/9788 [00:02<00:51, 185.19it/s]  2%|         | 241/9788 [00:02<00:41, 231.02it/s]  3%|         | 289/9788 [00:02<00:34, 272.92it/s]  3%|         | 337/9788 [00:02<00:30, 310.72it/s]  4%|         | 385/9788 [00:02<00:27, 343.10it/s]  4%|         | 433/9788 [00:02<00:25, 369.64it/s]  5%|         | 481/9788 [00:03<00:23, 390.06it/s]  5%|         | 529/9788 [00:03<00:22, 405.33it/s]  6%|         | 577/9788 [00:03<00:22, 416.91it/s]  6%|         | 625/9788 [00:03<00:21, 426.41it/s]  7%|         | 673/9788 [00:03<00:21, 433.92it/s]  7%|         | 721/9788 [00:03<00:20, 438.79it/s]  8%|         | 769/9788 [00:03<00:20, 442.19it/s]  8%|         | 817/9788 [00:03<00:20, 443.83it/s]  9%|         | 865/9788 [00:03<00:20, 444.27it/s]  9%|         | 913/9788 [00:03<00:19, 444.18it/s] 10%|         | 961/9788 [00:04<00:19, 443.85it/s] 10%|         | 1009/9788 [00:04<00:19, 443.17it/s] 11%|         | 1057/9788 [00:04<00:19, 443.08it/s] 11%|        | 1105/9788 [00:04<00:19, 443.40it/s] 12%|        | 1153/9788 [00:04<00:19, 444.23it/s] 12%|        | 1201/9788 [00:04<00:19, 444.01it/s] 13%|        | 1249/9788 [00:04<00:19, 444.53it/s] 13%|        | 1297/9788 [00:04<00:19, 446.06it/s] 14%|        | 1345/9788 [00:04<00:18, 448.53it/s] 14%|        | 1393/9788 [00:05<00:18, 451.09it/s] 15%|        | 1441/9788 [00:05<00:18, 452.87it/s] 15%|        | 1489/9788 [00:05<00:18, 453.90it/s] 16%|        | 1537/9788 [00:05<00:18, 452.56it/s] 16%|        | 1585/9788 [00:05<00:18, 451.87it/s] 17%|        | 1633/9788 [00:05<00:18, 451.85it/s] 17%|        | 1681/9788 [00:05<00:17, 452.74it/s] 18%|        | 1729/9788 [00:05<00:17, 452.22it/s] 18%|        | 1777/9788 [00:05<00:17, 451.58it/s] 19%|        | 1825/9788 [00:05<00:17, 451.41it/s] 19%|        | 1873/9788 [00:06<00:17, 450.53it/s] 20%|        | 1921/9788 [00:06<00:17, 450.83it/s] 20%|        | 1969/9788 [00:06<00:17, 451.23it/s] 21%|        | 2017/9788 [00:06<00:17, 453.03it/s] 21%|        | 2065/9788 [00:06<00:16, 454.31it/s] 22%|       | 2113/9788 [00:06<00:16, 454.81it/s] 22%|       | 2161/9788 [00:06<00:16, 456.02it/s] 23%|       | 2209/9788 [00:06<00:16, 457.46it/s] 23%|       | 2257/9788 [00:06<00:16, 457.04it/s] 24%|       | 2305/9788 [00:07<00:16, 456.80it/s] 24%|       | 2353/9788 [00:07<00:16, 456.26it/s] 25%|       | 2401/9788 [00:07<00:16, 457.88it/s] 25%|       | 2449/9788 [00:07<00:15, 458.72it/s] 26%|       | 2497/9788 [00:07<00:15, 458.72it/s] 26%|       | 2545/9788 [00:07<00:15, 458.22it/s] 26%|       | 2593/9788 [00:07<00:15, 457.92it/s] 27%|       | 2641/9788 [00:07<00:15, 456.17it/s] 27%|       | 2689/9788 [00:07<00:15, 456.61it/s] 28%|       | 2737/9788 [00:07<00:15, 456.70it/s] 28%|       | 2785/9788 [00:08<00:15, 458.75it/s] 29%|       | 2833/9788 [00:08<00:15, 459.49it/s] 29%|       | 2881/9788 [00:08<00:15, 460.15it/s] 30%|       | 2929/9788 [00:08<00:14, 459.61it/s] 30%|       | 2977/9788 [00:08<00:14, 459.07it/s] 31%|       | 3025/9788 [00:08<00:14, 457.25it/s] 31%|      | 3073/9788 [00:08<00:14, 456.52it/s] 32%|      | 3121/9788 [00:08<00:14, 456.57it/s] 32%|      | 3169/9788 [00:08<00:14, 458.79it/s] 33%|      | 3217/9788 [00:09<00:14, 460.04it/s] 33%|      | 3265/9788 [00:09<00:14, 460.07it/s] 34%|      | 3313/9788 [00:09<00:14, 459.71it/s] 34%|      | 3361/9788 [00:09<00:14, 458.81it/s] 35%|      | 3409/9788 [00:09<00:13, 457.05it/s] 35%|      | 3457/9788 [00:09<00:13, 455.84it/s] 36%|      | 3505/9788 [00:09<00:13, 454.54it/s] 36%|      | 3553/9788 [00:09<00:13, 455.40it/s] 37%|      | 3601/9788 [00:09<00:13, 455.46it/s] 37%|      | 3649/9788 [00:09<00:13, 456.63it/s] 38%|      | 3697/9788 [00:10<00:13, 456.86it/s] 38%|      | 3745/9788 [00:10<00:13, 457.77it/s] 39%|      | 3793/9788 [00:10<00:13, 458.08it/s] 39%|      | 3841/9788 [00:10<00:12, 459.08it/s] 40%|      | 3889/9788 [00:10<00:12, 460.42it/s] 40%|      | 3937/9788 [00:10<00:12, 461.71it/s] 41%|      | 3985/9788 [00:10<00:12, 459.69it/s] 41%|      | 4033/9788 [00:10<00:12, 460.44it/s] 42%|     | 4081/9788 [00:10<00:12, 462.12it/s] 42%|     | 4129/9788 [00:11<00:12, 463.22it/s] 43%|     | 4177/9788 [00:11<00:12, 462.74it/s] 43%|     | 4225/9788 [00:11<00:12, 462.47it/s] 44%|     | 4273/9788 [00:11<00:11, 461.28it/s] 44%|     | 4321/9788 [00:11<00:11, 460.26it/s] 45%|     | 4369/9788 [00:11<00:11, 458.24it/s] 45%|     | 4417/9788 [00:11<00:11, 457.68it/s] 46%|     | 4465/9788 [00:11<00:11, 458.69it/s] 46%|     | 4513/9788 [00:11<00:11, 458.18it/s] 47%|     | 4561/9788 [00:11<00:11, 458.37it/s] 47%|     | 4609/9788 [00:12<00:11, 457.75it/s] 48%|     | 4657/9788 [00:12<00:11, 457.58it/s] 48%|     | 4705/9788 [00:12<00:11, 456.12it/s] 49%|     | 4753/9788 [00:12<00:11, 455.06it/s] 49%|     | 4801/9788 [00:12<00:10, 454.01it/s] 50%|     | 4849/9788 [00:12<00:10, 454.06it/s] 50%|     | 4897/9788 [00:12<00:10, 455.61it/s] 51%|     | 4945/9788 [00:12<00:10, 452.28it/s] 51%|     | 4993/9788 [00:12<00:10, 453.49it/s] 52%|    | 5041/9788 [00:13<00:10, 454.88it/s] 52%|    | 5089/9788 [00:13<00:10, 457.05it/s] 52%|    | 5137/9788 [00:13<00:10, 458.79it/s] 53%|    | 5185/9788 [00:13<00:10, 459.17it/s] 53%|    | 5233/9788 [00:13<00:09, 459.14it/s] 54%|    | 5281/9788 [00:13<00:09, 459.02it/s] 54%|    | 5329/9788 [00:13<00:09, 458.88it/s] 55%|    | 5377/9788 [00:13<00:09, 458.69it/s] 55%|    | 5425/9788 [00:13<00:09, 458.48it/s] 56%|    | 5473/9788 [00:13<00:09, 458.31it/s] 56%|    | 5521/9788 [00:14<00:09, 457.32it/s] 57%|    | 5569/9788 [00:14<00:09, 456.23it/s] 57%|    | 5617/9788 [00:14<00:09, 456.76it/s] 58%|    | 5665/9788 [00:14<00:09, 457.92it/s] 58%|    | 5713/9788 [00:14<00:08, 458.40it/s] 59%|    | 5761/9788 [00:14<00:08, 458.20it/s] 59%|    | 5809/9788 [00:14<00:08, 458.57it/s] 60%|    | 5857/9788 [00:14<00:08, 459.76it/s] 60%|    | 5905/9788 [00:14<00:08, 457.13it/s] 61%|    | 5953/9788 [00:15<00:08, 458.57it/s] 61%|   | 6001/9788 [00:15<00:08, 459.82it/s] 62%|   | 6049/9788 [00:15<00:08, 460.77it/s] 62%|   | 6097/9788 [00:15<00:07, 461.38it/s] 63%|   | 6145/9788 [00:15<00:07, 462.75it/s] 63%|   | 6193/9788 [00:15<00:07, 462.93it/s] 64%|   | 6241/9788 [00:15<00:07, 462.88it/s] 64%|   | 6289/9788 [00:15<00:07, 464.54it/s] 65%|   | 6337/9788 [00:15<00:07, 465.62it/s] 65%|   | 6385/9788 [00:15<00:07, 467.17it/s] 66%|   | 6433/9788 [00:16<00:07, 468.22it/s] 66%|   | 6481/9788 [00:16<00:07, 469.78it/s] 67%|   | 6529/9788 [00:16<00:06, 470.49it/s] 67%|   | 6577/9788 [00:16<00:06, 471.68it/s] 68%|   | 6625/9788 [00:16<00:06, 470.80it/s] 68%|   | 6673/9788 [00:16<00:06, 471.44it/s] 69%|   | 6721/9788 [00:16<00:06, 470.64it/s] 69%|   | 6769/9788 [00:16<00:06, 471.41it/s] 70%|   | 6817/9788 [00:16<00:06, 470.44it/s] 70%|   | 6865/9788 [00:16<00:06, 468.15it/s] 71%|   | 6913/9788 [00:17<00:06, 468.56it/s] 71%|   | 6961/9788 [00:17<00:06, 469.48it/s] 72%|  | 7009/9788 [00:17<00:05, 469.16it/s] 72%|  | 7057/9788 [00:17<00:05, 469.62it/s] 73%|  | 7105/9788 [00:17<00:05, 469.74it/s] 73%|  | 7153/9788 [00:17<00:05, 470.23it/s] 74%|  | 7201/9788 [00:17<00:05, 470.85it/s] 74%|  | 7249/9788 [00:17<00:05, 472.63it/s] 75%|  | 7297/9788 [00:17<00:05, 474.20it/s] 75%|  | 7345/9788 [00:17<00:05, 475.89it/s] 76%|  | 7393/9788 [00:18<00:05, 476.95it/s] 76%|  | 7441/9788 [00:18<00:04, 470.10it/s] 77%|  | 7489/9788 [00:18<00:04, 471.93it/s] 77%|  | 7537/9788 [00:18<00:04, 472.08it/s] 77%|  | 7585/9788 [00:18<00:04, 471.21it/s] 78%|  | 7633/9788 [00:18<00:04, 469.47it/s] 78%|  | 7681/9788 [00:18<00:04, 470.25it/s] 79%|  | 7729/9788 [00:18<00:04, 471.70it/s] 79%|  | 7777/9788 [00:18<00:04, 472.91it/s] 80%|  | 7825/9788 [00:18<00:04, 471.56it/s] 80%|  | 7874/9788 [00:19<00:04, 476.98it/s] 81%|  | 7922/9788 [00:19<00:03, 477.81it/s] 81%| | 7970/9788 [00:19<00:03, 477.36it/s] 82%| | 8018/9788 [00:19<00:03, 476.16it/s] 82%| | 8066/9788 [00:19<00:03, 472.97it/s] 83%| | 8114/9788 [00:19<00:03, 470.20it/s] 83%| | 8162/9788 [00:19<00:03, 467.60it/s] 84%| | 8209/9788 [00:19<00:03, 464.51it/s] 84%| | 8257/9788 [00:19<00:03, 463.92it/s] 85%| | 8305/9788 [00:20<00:03, 464.13it/s] 85%| | 8353/9788 [00:20<00:03, 464.86it/s] 86%| | 8401/9788 [00:20<00:02, 466.56it/s] 86%| | 8449/9788 [00:20<00:02, 470.11it/s] 87%| | 8498/9788 [00:20<00:02, 475.94it/s] 87%| | 8549/9788 [00:20<00:02, 486.01it/s] 88%| | 8598/9788 [00:20<00:02, 486.26it/s] 88%| | 8647/9788 [00:20<00:02, 484.38it/s] 89%| | 8696/9788 [00:20<00:02, 483.17it/s] 89%| | 8745/9788 [00:20<00:02, 480.98it/s] 90%| | 8794/9788 [00:21<00:02, 476.58it/s] 90%| | 8842/9788 [00:21<00:01, 474.40it/s] 91%| | 8890/9788 [00:21<00:01, 472.51it/s] 91%|| 8938/9788 [00:21<00:01, 470.15it/s] 92%|| 8986/9788 [00:21<00:01, 470.44it/s] 92%|| 9034/9788 [00:21<00:01, 471.41it/s] 93%|| 9082/9788 [00:21<00:01, 471.51it/s] 93%|| 9130/9788 [00:21<00:01, 472.63it/s] 94%|| 9178/9788 [00:21<00:01, 473.98it/s] 94%|| 9226/9788 [00:21<00:01, 473.74it/s] 95%|| 9274/9788 [00:22<00:01, 473.29it/s] 95%|| 9322/9788 [00:22<00:00, 472.51it/s] 96%|| 9370/9788 [00:22<00:00, 472.69it/s] 96%|| 9418/9788 [00:22<00:00, 473.48it/s] 97%|| 9466/9788 [00:22<00:00, 475.26it/s] 97%|| 9514/9788 [00:22<00:00, 475.76it/s] 98%|| 9562/9788 [00:22<00:00, 476.23it/s] 98%|| 9610/9788 [00:22<00:00, 476.82it/s] 99%|| 9659/9788 [00:22<00:00, 480.62it/s] 99%|| 9708/9788 [00:22<00:00, 481.17it/s]100%|| 9757/9788 [00:23<00:00, 480.14it/s]100%|| 9788/9788 [00:23<00:00, 423.11it/s]
2024-01-16:01:17:49,529 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:01:17:49,529 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:01:17:49,529 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:01:17:49,529 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:01:17:49,529 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:01:17:49,529 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:01:17:49,529 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
  0%|          | 0/8 [00:00<?, ?it/s]2024-01-16:01:17:49,529 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
 12%|        | 1/8 [00:00<00:01,  5.86it/s] 25%|       | 2/8 [00:00<00:01,  3.06it/s] 38%|      | 3/8 [00:00<00:01,  3.00it/s] 50%|     | 4/8 [00:01<00:01,  3.20it/s] 62%|   | 5/8 [00:01<00:00,  3.03it/s] 75%|  | 6/8 [00:01<00:00,  3.11it/s]100%|| 8/8 [00:02<00:00,  4.31it/s]100%|| 8/8 [00:02<00:00,  3.68it/s]
bootstrapping for stddev: perplexity
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:01<01:40,  1.02s/it]  9%|         | 9/100 [00:01<00:08, 10.52it/s] 97%|| 97/100 [00:01<00:00, 128.74it/s]100%|| 100/100 [00:01<00:00, 67.72it/s]
hf (pretrained=EleutherAI/pythia-410m), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 16
|    Tasks     |Version|Filter|n-shot|    Metric     | Value |   |Stderr|
|--------------|------:|------|-----:|---------------|------:|---|------|
|arc_challenge |      1|none  |     0|acc            | 0.2108|  |0.0119|
|              |       |none  |     0|acc_norm       | 0.2491|  |0.0126|
|arc_easy      |      1|none  |     0|acc            | 0.5215|  |0.0103|
|              |       |none  |     0|acc_norm       | 0.4596|  |0.0102|
|boolq         |      2|none  |     0|acc            | 0.5988|  |0.0086|
|hellaswag     |      1|none  |     0|acc            | 0.3388|  |0.0047|
|              |       |none  |     0|acc_norm       | 0.4053|  |0.0049|
|lambada_openai|      1|none  |     0|perplexity     |11.8967|  |0.3572|
|              |       |none  |     0|acc            | 0.4993|  |0.0070|
|openbookqa    |      1|none  |     0|acc            | 0.1800|  |0.0172|
|              |       |none  |     0|acc_norm       | 0.2900|  |0.0203|
|piqa          |      1|none  |     0|acc            | 0.6621|  |0.0110|
|              |       |none  |     0|acc_norm       | 0.6687|  |0.0110|
|sciq          |      1|none  |     0|acc            | 0.8040|  |0.0126|
|              |       |none  |     0|acc_norm       | 0.7080|  |0.0144|
|wikitext      |      2|none  |     0|word_perplexity|20.3621|  |N/A   |
|              |       |none  |     0|byte_perplexity| 1.7569|  |N/A   |
|              |       |none  |     0|bits_per_byte  | 0.8131|  |N/A   |
|winogrande    |      1|none  |     0|acc            | 0.5478|  |0.0140|

