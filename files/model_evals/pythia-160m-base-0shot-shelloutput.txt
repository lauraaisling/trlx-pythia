The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `8`
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-01-16:00:55:04,124 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:00:55:04,124 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:00:55:04,124 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:00:55:04,124 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:00:55:04,125 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:00:55:04,125 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:00:55:04,125 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:00:55:04,125 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:00:55:04,126 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:00:55:04,126 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:00:55:04,173 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:00:55:04,173 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:00:55:04,176 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:00:55:04,176 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:00:55:04,180 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:00:55:04,180 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:00:55:04,680 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:00:55:04,681 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:00:55:04,682 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:00:55:04,683 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:00:55:04,684 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:00:55:04,705 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:00:55:04,710 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:00:55:04,718 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:00:55:09,238 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:00:55:09,238 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:00:55:09,242 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:00:55:09,276 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:00:55:09,287 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:00:55:09,295 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:00:55:09,315 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:00:55:09,414 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:00:55:16,085 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:55:16,086 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:55:16,205 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:55:16,222 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:55:16,418 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:55:16,505 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:00:55:17,464 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:55:17,516 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:00:56:10,686 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:56:10,692 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:00:56:10,890 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:56:10,895 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:00:56:10,912 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:56:10,916 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:00:56:11,144 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:56:11,148 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:00:56:11,344 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:56:11,348 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:00:56:11,612 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:56:11,616 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:00:56:11,900 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:56:11,905 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:00:56:12,984 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:56:12,988 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-01-16:00:56:15,962 INFO     [huggingface.py:298] Using 8 devices with data parallelism
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-01-16:00:56:22,584 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:00:56:22,584 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:00:56:22,668 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:00:56:22,668 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:00:56:22,694 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:00:56:22,694 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:00:56:22,702 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:00:56:22,702 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:00:56:22,717 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:00:56:22,717 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:00:56:22,935 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:00:56:22,935 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:00:56:23,236 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:00:56:23,236 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:00:56:23,866 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:00:56:23,866 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:00:56:31,800 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:56:31,800 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:56:31,931 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:56:31,931 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:56:31,943 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:56:31,943 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:56:31,994 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:56:31,994 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:56:32,317 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:56:32,317 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:56:32,376 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:56:32,376 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:56:32,692 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:56:32,693 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:56:32,959 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:56:32,959 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:56:42,788 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:56:42,788 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:56:42,788 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:56:42,788 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:56:42,788 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:00:56:42,788 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:56:42,821 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:56:42,821 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:56:42,821 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:56:42,821 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:56:42,821 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:00:56:42,821 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:56:42,881 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:56:42,881 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:56:42,881 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:56:42,881 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:56:42,881 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:00:56:42,881 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:56:42,920 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:56:42,921 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:56:42,921 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:56:42,921 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:56:42,921 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:00:56:42,921 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:56:43,008 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:56:43,008 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:56:43,008 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:56:43,008 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:56:43,008 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:00:56:43,008 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:56:43,363 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:56:43,363 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:56:43,363 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:56:43,363 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:56:43,363 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:00:56:43,363 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:56:43,857 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:56:43,858 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:56:43,858 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:56:43,858 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:56:43,858 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:00:56:43,858 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:56:44,018 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:56:44,019 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:56:44,019 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:56:44,019 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:56:44,019 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:00:56:44,019 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:56:47,488 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:00:56:47,488 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:00:56:47,488 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:00:56:47,488 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:00:56:47,488 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:00:56:47,488 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:00:56:47,488 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:00:56:47,488 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:00:56:47,488 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:00:56:47,488 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:00:56:47,489 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:00:56:47,521 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:00:56:47,521 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:00:56:47,521 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:00:56:47,521 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:00:56:47,521 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:00:56:47,521 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:00:56:47,521 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:00:56:47,521 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:00:56:47,521 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:00:56:47,522 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:00:56:47,522 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:00:56:47,792 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:00:56:47,792 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:00:56:47,792 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:00:56:47,792 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:00:56:47,792 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:00:56:47,792 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:00:56:47,792 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:00:56:47,792 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:00:56:47,792 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:00:56:47,792 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:00:56:47,792 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:00:56:47,793 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:00:56:47,794 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:00:56:47,794 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:00:56:47,794 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:00:56:47,794 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:00:56:47,794 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:00:56:47,794 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:00:56:47,794 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:00:56:47,794 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:00:56:47,794 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:00:56:47,794 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:00:56:47,968 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:00:56:47,968 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:00:56:47,968 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:00:56:47,968 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:00:56:47,968 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:00:56:47,968 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:00:56:47,968 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:00:56:47,968 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:00:56:47,968 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:00:56:47,968 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:00:56:47,968 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:00:56:48,380 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:00:56:48,381 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:00:56:48,381 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:00:56:48,381 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:00:56:48,381 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:00:56:48,381 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:00:56:48,381 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:00:56:48,381 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:00:56:48,381 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:00:56:48,381 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:00:56:48,381 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:00:56:48,652 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:00:56:48,652 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:00:56:48,652 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:00:56:48,652 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:00:56:48,652 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:00:56:48,652 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:00:56:48,652 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:00:56:48,652 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:00:56:48,652 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:00:56:48,652 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:00:56:48,653 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:00:56:48,852 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:00:56:48,852 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:00:56:48,853 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:00:56:48,853 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:00:56:48,853 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:00:56:48,853 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:00:56:48,853 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:00:56:48,853 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:00:56:48,853 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:00:56:48,853 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:00:56:48,853 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:00:57:00,624 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:00:57:00,624 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:00:57:00,624 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:00:57:00,624 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:00:57:00,624 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:00:57:00,625 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:00:57:00,626 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:00:57:00,627 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:00:57:01,076 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:00:57:01,076 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:00:57:01,076 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:00:57:01,076 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:00:57:01,076 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:00:57:01,076 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:00:57:01,076 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:00:57:01,076 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:00:57:01,405 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:00:57:01,405 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:00:57:01,405 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:00:57:01,405 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:00:57:01,406 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:00:57:01,406 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:00:57:01,406 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:00:57:01,409 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:00:57:02,866 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:00:57:02,866 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:00:57:02,866 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:00:57:02,866 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:00:57:02,867 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:00:57:02,867 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:00:57:02,867 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:00:57:02,867 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:00:57:03,988 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:00:57:03,988 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:00:57:03,988 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:00:57:03,988 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:00:57:03,988 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:00:57:03,988 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:00:57:03,988 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:00:57:03,988 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:00:57:04,043 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:00:57:04,043 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:00:57:04,043 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:00:57:04,043 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:00:57:04,043 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:00:57:04,043 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:00:57:04,043 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:00:57:04,043 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:00:57:04,310 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:00:57:04,310 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:00:57:04,310 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:00:57:04,310 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:00:57:04,310 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:00:57:04,310 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:00:57:04,310 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:00:57:04,310 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:00:57:04,502 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:00:57:04,502 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:00:57:04,502 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:00:57:04,502 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:00:57:04,502 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:00:57:04,502 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:00:57:04,502 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:00:57:04,502 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:00:57:04,523 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:00:57:04,523 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:00:57:04,523 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:00:57:04,523 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:00:57:04,523 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:00:57:04,523 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:00:57:04,523 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:00:57:04,523 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:00:57:04,561 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:00:57:04,561 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:00:57:04,561 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:00:57:04,561 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:00:57:04,561 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:00:57:04,561 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:00:57:04,561 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:00:57:04,561 INFO     [evaluator.py:314] Running loglikelihood requests
  0%|          | 0/9788 [00:00<?, ?it/s]  0%|          | 1/9788 [00:01<4:28:30,  1.65s/it]  1%|          | 49/9788 [00:01<04:12, 38.60it/s]   1%|          | 113/9788 [00:01<01:39, 97.72it/s]  2%|         | 177/9788 [00:01<00:59, 162.86it/s]  2%|         | 241/9788 [00:02<00:41, 230.80it/s]  3%|         | 305/9788 [00:02<00:31, 297.12it/s]  4%|         | 369/9788 [00:02<00:26, 358.45it/s]  4%|         | 433/9788 [00:02<00:22, 411.54it/s]  5%|         | 497/9788 [00:02<00:20, 456.47it/s]  6%|         | 561/9788 [00:02<00:18, 493.27it/s]  6%|         | 625/9788 [00:02<00:17, 523.03it/s]  7%|         | 689/9788 [00:02<00:16, 546.32it/s]  8%|         | 753/9788 [00:02<00:16, 563.85it/s]  8%|         | 817/9788 [00:03<00:15, 576.77it/s]  9%|         | 881/9788 [00:03<00:15, 587.81it/s] 10%|         | 945/9788 [00:03<00:14, 596.28it/s] 10%|         | 1009/9788 [00:03<00:14, 602.22it/s] 11%|         | 1073/9788 [00:03<00:14, 600.96it/s] 12%|        | 1137/9788 [00:03<00:14, 604.33it/s] 12%|        | 1201/9788 [00:03<00:14, 607.72it/s] 13%|        | 1265/9788 [00:03<00:13, 611.30it/s] 14%|        | 1329/9788 [00:03<00:13, 615.54it/s] 14%|        | 1393/9788 [00:03<00:13, 617.08it/s] 15%|        | 1457/9788 [00:04<00:13, 617.55it/s] 16%|        | 1521/9788 [00:04<00:13, 618.75it/s] 16%|        | 1585/9788 [00:04<00:13, 620.70it/s] 17%|        | 1649/9788 [00:04<00:13, 620.97it/s] 18%|        | 1713/9788 [00:04<00:12, 621.81it/s] 18%|        | 1777/9788 [00:04<00:12, 621.33it/s] 19%|        | 1841/9788 [00:04<00:12, 621.02it/s] 19%|        | 1905/9788 [00:04<00:12, 620.78it/s] 20%|        | 1969/9788 [00:04<00:12, 620.83it/s] 21%|        | 2033/9788 [00:05<00:12, 620.25it/s] 21%|       | 2097/9788 [00:05<00:12, 620.75it/s] 22%|       | 2161/9788 [00:05<00:12, 621.11it/s] 23%|       | 2225/9788 [00:05<00:12, 622.33it/s] 23%|       | 2289/9788 [00:05<00:12, 623.12it/s] 24%|       | 2353/9788 [00:05<00:11, 621.17it/s] 25%|       | 2417/9788 [00:05<00:11, 621.58it/s] 25%|       | 2481/9788 [00:05<00:11, 623.18it/s] 26%|       | 2545/9788 [00:05<00:11, 621.53it/s] 27%|       | 2609/9788 [00:05<00:11, 621.48it/s] 27%|       | 2673/9788 [00:06<00:11, 620.79it/s] 28%|       | 2737/9788 [00:06<00:11, 621.27it/s] 29%|       | 2801/9788 [00:06<00:11, 621.97it/s] 29%|       | 2865/9788 [00:06<00:11, 621.20it/s] 30%|       | 2929/9788 [00:06<00:11, 622.22it/s] 31%|       | 2993/9788 [00:06<00:10, 625.18it/s] 31%|       | 3057/9788 [00:06<00:10, 627.47it/s] 32%|      | 3121/9788 [00:06<00:10, 628.25it/s] 33%|      | 3185/9788 [00:06<00:10, 629.08it/s] 33%|      | 3249/9788 [00:06<00:10, 628.85it/s] 34%|      | 3313/9788 [00:07<00:10, 629.47it/s] 35%|      | 3377/9788 [00:07<00:10, 629.58it/s] 35%|      | 3441/9788 [00:07<00:10, 627.65it/s] 36%|      | 3505/9788 [00:07<00:10, 627.54it/s] 36%|      | 3569/9788 [00:07<00:09, 629.27it/s] 37%|      | 3633/9788 [00:07<00:09, 628.19it/s] 38%|      | 3697/9788 [00:07<00:09, 629.45it/s] 38%|      | 3761/9788 [00:07<00:09, 631.71it/s] 39%|      | 3825/9788 [00:07<00:09, 631.82it/s] 40%|      | 3889/9788 [00:07<00:09, 633.07it/s] 40%|      | 3953/9788 [00:08<00:09, 634.52it/s] 41%|      | 4017/9788 [00:08<00:09, 634.76it/s] 42%|     | 4081/9788 [00:08<00:08, 634.51it/s] 42%|     | 4145/9788 [00:08<00:08, 635.25it/s] 43%|     | 4209/9788 [00:08<00:08, 633.55it/s] 44%|     | 4273/9788 [00:08<00:08, 634.82it/s] 44%|     | 4337/9788 [00:08<00:08, 634.84it/s] 45%|     | 4401/9788 [00:08<00:08, 634.25it/s] 46%|     | 4465/9788 [00:08<00:08, 634.28it/s] 46%|     | 4529/9788 [00:08<00:08, 634.38it/s] 47%|     | 4593/9788 [00:09<00:08, 633.88it/s] 48%|     | 4657/9788 [00:09<00:08, 634.94it/s] 48%|     | 4723/9788 [00:09<00:07, 642.21it/s] 49%|     | 4791/9788 [00:09<00:07, 653.32it/s] 50%|     | 4862/9788 [00:09<00:07, 670.14it/s] 50%|     | 4930/9788 [00:09<00:07, 630.43it/s] 51%|     | 4994/9788 [00:09<00:07, 632.37it/s] 52%|    | 5058/9788 [00:09<00:07, 633.06it/s] 52%|    | 5122/9788 [00:09<00:07, 633.58it/s] 53%|    | 5186/9788 [00:10<00:07, 634.30it/s] 54%|    | 5250/9788 [00:10<00:07, 634.69it/s] 54%|    | 5314/9788 [00:10<00:07, 634.58it/s] 55%|    | 5387/9788 [00:10<00:06, 662.64it/s] 56%|    | 5457/9788 [00:10<00:06, 632.34it/s] 56%|    | 5526/9788 [00:10<00:06, 648.68it/s] 57%|    | 5592/9788 [00:10<00:06, 651.10it/s] 58%|    | 5658/9788 [00:10<00:06, 653.33it/s] 58%|    | 5724/9788 [00:10<00:06, 655.13it/s] 59%|    | 5790/9788 [00:10<00:06, 655.98it/s] 60%|    | 5857/9788 [00:11<00:06, 619.27it/s] 61%|    | 5931/9788 [00:11<00:05, 653.40it/s] 61%|   | 5999/9788 [00:11<00:05, 661.07it/s] 62%|   | 6066/9788 [00:11<00:05, 624.29it/s] 63%|   | 6135/9788 [00:11<00:05, 642.76it/s] 63%|   | 6206/9788 [00:11<00:05, 661.87it/s] 64%|   | 6273/9788 [00:11<00:05, 623.35it/s] 65%|   | 6344/9788 [00:11<00:05, 647.50it/s] 66%|   | 6415/9788 [00:11<00:05, 665.38it/s] 66%|   | 6483/9788 [00:12<00:05, 631.30it/s] 67%|   | 6547/9788 [00:12<00:05, 631.18it/s] 68%|   | 6620/9788 [00:12<00:04, 659.31it/s] 68%|   | 6689/9788 [00:12<00:04, 629.15it/s] 69%|   | 6764/9788 [00:12<00:04, 662.79it/s] 70%|   | 6833/9788 [00:12<00:04, 634.12it/s] 71%|   | 6913/9788 [00:12<00:04, 641.75it/s] 71%|  | 6993/9788 [00:12<00:04, 647.77it/s] 72%|  | 7073/9788 [00:12<00:04, 653.13it/s] 73%|  | 7153/9788 [00:13<00:04, 655.87it/s] 74%|  | 7231/9788 [00:13<00:03, 688.69it/s] 75%|  | 7301/9788 [00:13<00:03, 651.89it/s] 75%|  | 7370/9788 [00:13<00:03, 662.08it/s] 76%|  | 7441/9788 [00:13<00:03, 637.70it/s] 77%|  | 7521/9788 [00:13<00:03, 644.81it/s] 78%|  | 7601/9788 [00:13<00:03, 646.00it/s] 78%|  | 7681/9788 [00:13<00:03, 650.45it/s] 79%|  | 7761/9788 [00:13<00:03, 654.75it/s] 80%|  | 7841/9788 [00:14<00:02, 657.10it/s] 81%|  | 7921/9788 [00:14<00:02, 657.95it/s] 82%| | 8000/9788 [00:14<00:02, 692.59it/s] 82%| | 8070/9788 [00:14<00:02, 657.99it/s] 83%| | 8145/9788 [00:14<00:02, 646.33it/s] 84%| | 8225/9788 [00:14<00:02, 651.26it/s] 85%| | 8305/9788 [00:14<00:02, 654.03it/s] 86%| | 8384/9788 [00:14<00:02, 689.86it/s] 86%| | 8454/9788 [00:15<00:02, 656.63it/s] 87%| | 8529/9788 [00:15<00:01, 644.19it/s] 88%| | 8609/9788 [00:15<00:01, 648.06it/s] 89%| | 8687/9788 [00:15<00:01, 682.89it/s] 89%| | 8756/9788 [00:15<00:01, 649.93it/s] 90%| | 8829/9788 [00:15<00:01, 671.58it/s] 91%| | 8897/9788 [00:15<00:01, 635.96it/s] 92%|| 8962/9788 [00:15<00:01, 637.57it/s] 92%|| 9041/9788 [00:15<00:01, 642.78it/s] 93%|| 9121/9788 [00:16<00:01, 648.03it/s] 94%|| 9198/9788 [00:16<00:00, 681.00it/s] 95%|| 9267/9788 [00:16<00:00, 646.88it/s] 95%|| 9343/9788 [00:16<00:00, 677.77it/s] 96%|| 9412/9788 [00:16<00:00, 646.09it/s] 97%|| 9489/9788 [00:16<00:00, 651.22it/s] 98%|| 9569/9788 [00:16<00:00, 664.56it/s] 99%|| 9649/9788 [00:16<00:00, 671.58it/s] 99%|| 9729/9788 [00:16<00:00, 676.44it/s]100%|| 9788/9788 [00:17<00:00, 574.39it/s]
2024-01-16:00:57:25,777 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:00:57:25,777 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:00:57:25,777 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:00:57:25,777 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:00:57:25,777 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:00:57:25,777 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:00:57:25,777 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:00:57:25,777 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
  0%|          | 0/8 [00:00<?, ?it/s] 25%|       | 2/8 [00:00<00:00,  6.85it/s] 38%|      | 3/8 [00:00<00:00,  6.68it/s] 50%|     | 4/8 [00:00<00:00,  6.98it/s] 62%|   | 5/8 [00:00<00:00,  6.63it/s] 75%|  | 6/8 [00:00<00:00,  6.90it/s]100%|| 8/8 [00:01<00:00,  9.44it/s]100%|| 8/8 [00:01<00:00,  7.94it/s]
bootstrapping for stddev: perplexity
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:01<01:54,  1.16s/it] 97%|| 97/100 [00:01<00:00, 88.24it/s]100%|| 100/100 [00:01<00:00, 66.64it/s]
hf (pretrained=EleutherAI/pythia-160m), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 16
|    Tasks     |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|--------------|------:|------|-----:|---------------|-----:|---|------|
|arc_challenge |      1|none  |     0|acc            |0.2287|  |0.0123|
|              |       |none  |     0|acc_norm       |0.2389|  |0.0125|
|arc_easy      |      1|none  |     0|acc            |0.2757|  |0.0092|
|              |       |none  |     0|acc_norm       |0.2727|  |0.0091|
|boolq         |      2|none  |     0|acc            |0.3875|  |0.0085|
|hellaswag     |      1|none  |     0|acc            |0.2514|  |0.0043|
|              |       |none  |     0|acc_norm       |0.2521|  |0.0043|
|lambada_openai|      1|none  |     0|perplexity     |   NaN|  |NaN   |
|              |       |none  |     0|acc            |0.0999|  |0.0042|
|openbookqa    |      1|none  |     0|acc            |0.1960|  |0.0178|
|              |       |none  |     0|acc_norm       |0.2440|  |0.0192|
|piqa          |      1|none  |     0|acc            |0.5370|  |0.0116|
|              |       |none  |     0|acc_norm       |0.5326|  |0.0116|
|sciq          |      1|none  |     0|acc            |0.0270|  |0.0051|
|              |       |none  |     0|acc_norm       |0.0310|  |0.0055|
|wikitext      |      2|none  |     0|word_perplexity|   NaN|  |N/A   |
|              |       |none  |     0|byte_perplexity|   NaN|  |N/A   |
|              |       |none  |     0|bits_per_byte  |   NaN|  |N/A   |
|winogrande    |      1|none  |     0|acc            |0.4980|  |0.0141|

