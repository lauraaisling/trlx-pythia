The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `8`
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-01-16:00:51:27,050 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:00:51:27,050 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:00:51:27,051 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:00:51:27,051 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:00:51:27,090 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:00:51:27,090 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:00:51:27,101 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:00:51:27,101 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:00:51:27,175 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:00:51:27,175 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:00:51:27,178 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:00:51:27,178 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:00:51:27,194 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:00:51:27,195 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:00:51:27,208 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:00:51:27,208 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:00:51:27,600 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:00:51:27,636 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:00:51:27,637 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:00:51:27,674 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:00:51:27,738 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:00:51:27,754 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:00:51:27,779 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:00:51:27,784 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:00:51:32,137 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:00:51:32,140 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:00:51:32,284 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:00:51:32,289 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:00:51:32,308 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:00:51:32,351 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:00:51:32,414 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:00:51:32,487 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:00:51:39,198 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:51:39,291 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:51:39,452 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:51:39,517 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:51:39,641 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:51:39,801 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:00:51:40,540 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:00:51:40,824 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:00:52:32,587 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:52:32,593 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:00:52:32,645 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:52:32,651 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:00:52:32,667 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:52:32,671 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:00:52:33,346 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:52:33,351 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:00:52:34,575 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:52:34,579 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:00:52:34,768 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:52:34,773 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:00:52:35,108 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:52:35,112 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:00:52:35,707 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:00:52:35,711 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-01-16:00:52:37,226 INFO     [huggingface.py:298] Using 8 devices with data parallelism
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-01-16:00:52:44,302 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:00:52:44,303 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:00:52:44,322 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:00:52:44,322 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:00:52:44,363 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:00:52:44,363 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:00:52:44,921 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:00:52:44,921 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:00:52:45,525 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:00:52:45,525 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:00:52:45,988 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:00:52:45,988 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:00:52:46,919 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:00:52:46,919 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:00:52:46,999 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:00:52:46,999 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:00:52:53,707 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:52:53,707 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:52:53,711 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:52:53,711 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:52:53,936 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:52:53,936 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:52:54,486 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:52:54,486 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:52:54,657 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:52:54,657 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:52:55,161 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:52:55,162 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:52:55,965 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:52:55,965 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:52:56,218 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:52:56,218 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:00:53:04,204 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:53:04,204 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:53:04,204 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:53:04,204 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:53:04,204 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:00:53:04,204 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:53:05,179 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:53:05,179 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:53:05,179 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:53:05,179 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:53:05,179 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:00:53:05,179 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:53:05,689 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:53:05,689 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:53:05,690 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:53:05,690 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:53:05,690 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:00:53:05,690 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:53:05,797 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:53:05,797 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:53:05,797 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:53:05,797 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:53:05,797 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:00:53:05,797 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:53:06,311 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:53:06,311 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:53:06,311 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:53:06,311 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:53:06,311 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:00:53:06,311 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:53:06,925 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:53:06,925 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:53:06,925 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:53:06,925 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:53:06,925 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:00:53:06,925 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:53:06,962 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:53:06,962 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:53:06,962 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:53:06,962 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:53:06,962 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:00:53:06,962 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:53:07,191 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:53:07,191 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:53:07,191 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:00:53:07,191 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:53:07,191 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:00:53:07,191 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:00:53:08,840 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 5
2024-01-16:00:53:08,840 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 5
2024-01-16:00:53:08,840 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 5
2024-01-16:00:53:08,840 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 5
2024-01-16:00:53:08,840 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 5
2024-01-16:00:53:08,840 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 5
2024-01-16:00:53:08,840 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 5
2024-01-16:00:53:08,840 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 5
2024-01-16:00:53:08,840 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 5
2024-01-16:00:53:08,840 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 5
2024-01-16:00:53:08,841 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:00:53:09,819 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 5
2024-01-16:00:53:09,820 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 5
2024-01-16:00:53:09,820 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 5
2024-01-16:00:53:09,820 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 5
2024-01-16:00:53:09,820 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 5
2024-01-16:00:53:09,820 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 5
2024-01-16:00:53:09,820 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 5
2024-01-16:00:53:09,820 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 5
2024-01-16:00:53:09,820 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 5
2024-01-16:00:53:09,820 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 5
2024-01-16:00:53:09,820 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:00:53:10,232 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 5
2024-01-16:00:53:10,233 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 5
2024-01-16:00:53:10,233 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 5
2024-01-16:00:53:10,233 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 5
2024-01-16:00:53:10,233 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 5
2024-01-16:00:53:10,233 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 5
2024-01-16:00:53:10,233 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 5
2024-01-16:00:53:10,233 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 5
2024-01-16:00:53:10,233 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 5
2024-01-16:00:53:10,233 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 5
2024-01-16:00:53:10,233 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:00:53:10,260 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 5
2024-01-16:00:53:10,261 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 5
2024-01-16:00:53:10,261 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 5
2024-01-16:00:53:10,261 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 5
2024-01-16:00:53:10,261 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 5
2024-01-16:00:53:10,261 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 5
2024-01-16:00:53:10,261 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 5
2024-01-16:00:53:10,261 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 5
2024-01-16:00:53:10,261 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 5
2024-01-16:00:53:10,261 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 5
2024-01-16:00:53:10,262 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:00:53:11,228 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 5
2024-01-16:00:53:11,228 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 5
2024-01-16:00:53:11,228 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 5
2024-01-16:00:53:11,229 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 5
2024-01-16:00:53:11,229 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 5
2024-01-16:00:53:11,229 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 5
2024-01-16:00:53:11,229 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 5
2024-01-16:00:53:11,229 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 5
2024-01-16:00:53:11,229 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 5
2024-01-16:00:53:11,229 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 5
2024-01-16:00:53:11,229 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:00:53:11,443 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 5
2024-01-16:00:53:11,443 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 5
2024-01-16:00:53:11,443 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 5
2024-01-16:00:53:11,443 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 5
2024-01-16:00:53:11,443 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 5
2024-01-16:00:53:11,443 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 5
2024-01-16:00:53:11,443 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 5
2024-01-16:00:53:11,443 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 5
2024-01-16:00:53:11,443 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 5
2024-01-16:00:53:11,443 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 5
2024-01-16:00:53:11,444 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:00:53:11,517 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 5
2024-01-16:00:53:11,518 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 5
2024-01-16:00:53:11,518 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 5
2024-01-16:00:53:11,518 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 5
2024-01-16:00:53:11,518 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 5
2024-01-16:00:53:11,518 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 5
2024-01-16:00:53:11,518 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 5
2024-01-16:00:53:11,518 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 5
2024-01-16:00:53:11,518 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 5
2024-01-16:00:53:11,518 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 5
2024-01-16:00:53:11,518 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:00:53:11,784 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 5
2024-01-16:00:53:11,785 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 5
2024-01-16:00:53:11,785 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 5
2024-01-16:00:53:11,785 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 5
2024-01-16:00:53:11,785 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 5
2024-01-16:00:53:11,785 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 5
2024-01-16:00:53:11,785 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 5
2024-01-16:00:53:11,785 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 5
2024-01-16:00:53:11,785 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 5
2024-01-16:00:53:11,785 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 5
2024-01-16:00:53:11,785 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:00:53:25,687 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:00:53:25,687 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:00:53:25,687 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:00:53:25,687 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:00:53:25,687 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:00:53:25,687 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:00:53:25,687 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:00:53:25,687 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:00:53:30,212 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:00:53:30,212 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:00:53:30,212 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:00:53:30,212 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:00:53:30,212 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:00:53:30,212 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:00:53:30,212 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:00:53:30,212 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:00:53:32,346 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:00:53:32,346 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:00:53:32,346 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:00:53:32,346 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:00:53:32,346 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:00:53:32,347 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:00:53:32,346 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:00:53:32,348 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:00:53:44,213 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:00:53:44,213 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:00:53:44,213 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:00:53:44,213 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:00:53:44,213 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:00:53:44,213 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:00:53:44,213 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:00:53:44,213 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:00:53:52,519 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:00:53:52,519 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:00:53:52,519 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:00:53:52,519 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:00:53:52,519 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:00:53:52,519 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:00:53:52,519 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:00:53:52,519 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:00:53:53,301 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:00:53:53,301 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:00:53:53,301 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:00:53:53,301 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:00:53:53,301 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:00:53:53,301 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:00:53:53,301 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:00:53:53,301 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:00:53:54,913 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:00:53:54,913 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:00:53:54,913 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:00:53:54,913 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:00:53:54,913 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:00:53:54,913 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:00:53:54,913 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:00:53:54,913 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:00:53:56,135 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:00:53:56,135 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:00:53:56,135 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:00:53:56,135 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:00:53:56,135 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:00:53:56,135 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:00:53:56,135 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:00:53:56,135 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:00:53:56,234 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:00:53:56,234 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:00:53:56,234 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:00:53:56,234 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:00:53:56,234 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:00:53:56,234 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:00:53:56,234 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:00:53:56,234 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:00:53:56,284 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:00:53:56,284 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:00:53:56,284 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:00:53:56,284 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:00:53:56,284 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:00:53:56,284 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:00:53:56,284 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:00:53:56,284 INFO     [evaluator.py:314] Running loglikelihood requests
  0%|          | 0/9788 [00:00<?, ?it/s]  0%|          | 1/9788 [00:01<4:57:51,  1.83s/it]  0%|          | 33/9788 [00:01<06:58, 23.29it/s]   1%|          | 65/9788 [00:02<03:14, 50.00it/s]  1%|          | 97/9788 [00:02<02:01, 79.86it/s]  1%|         | 129/9788 [00:02<01:26, 111.58it/s]  2%|         | 161/9788 [00:02<01:06, 144.17it/s]  2%|         | 193/9788 [00:02<00:54, 176.84it/s]  2%|         | 240/9788 [00:02<00:39, 238.79it/s]  3%|         | 275/9788 [00:02<00:39, 241.27it/s]  3%|         | 321/9788 [00:02<00:35, 268.55it/s]  4%|         | 369/9788 [00:03<00:32, 294.28it/s]  4%|         | 417/9788 [00:03<00:29, 315.74it/s]  5%|         | 465/9788 [00:03<00:27, 333.13it/s]  5%|         | 513/9788 [00:03<00:26, 348.35it/s]  6%|         | 561/9788 [00:03<00:25, 360.07it/s]  6%|         | 609/9788 [00:03<00:24, 374.60it/s]  7%|         | 657/9788 [00:03<00:23, 382.31it/s]  7%|         | 705/9788 [00:03<00:23, 393.07it/s]  8%|         | 753/9788 [00:03<00:22, 402.06it/s]  8%|         | 801/9788 [00:04<00:21, 411.07it/s]  9%|         | 849/9788 [00:04<00:21, 418.38it/s]  9%|         | 897/9788 [00:04<00:20, 428.14it/s] 10%|         | 945/9788 [00:04<00:20, 439.28it/s] 10%|         | 993/9788 [00:04<00:19, 447.17it/s] 11%|         | 1046/9788 [00:04<00:18, 470.69it/s] 11%|        | 1105/9788 [00:04<00:18, 468.08it/s] 12%|        | 1169/9788 [00:04<00:18, 478.44it/s] 13%|        | 1233/9788 [00:04<00:17, 486.81it/s] 13%|        | 1297/9788 [00:05<00:17, 497.24it/s] 14%|        | 1361/9788 [00:05<00:16, 505.73it/s] 15%|        | 1425/9788 [00:05<00:16, 510.35it/s] 15%|        | 1489/9788 [00:05<00:16, 512.25it/s] 16%|        | 1553/9788 [00:05<00:15, 516.93it/s] 17%|        | 1617/9788 [00:05<00:15, 517.89it/s] 17%|        | 1681/9788 [00:05<00:15, 520.75it/s] 18%|        | 1745/9788 [00:05<00:15, 521.54it/s] 18%|        | 1809/9788 [00:06<00:15, 523.42it/s] 19%|        | 1873/9788 [00:06<00:15, 524.96it/s] 20%|        | 1937/9788 [00:06<00:14, 526.61it/s] 20%|        | 2001/9788 [00:06<00:14, 528.05it/s] 21%|        | 2065/9788 [00:06<00:14, 530.11it/s] 22%|       | 2129/9788 [00:06<00:14, 531.91it/s] 22%|       | 2193/9788 [00:06<00:14, 534.06it/s] 23%|       | 2257/9788 [00:06<00:13, 538.61it/s] 24%|       | 2321/9788 [00:07<00:13, 542.57it/s] 24%|       | 2385/9788 [00:07<00:13, 547.81it/s] 25%|       | 2449/9788 [00:07<00:13, 552.74it/s] 26%|       | 2513/9788 [00:07<00:13, 554.58it/s] 26%|       | 2577/9788 [00:07<00:13, 554.09it/s] 27%|       | 2641/9788 [00:07<00:12, 556.52it/s] 28%|       | 2705/9788 [00:07<00:12, 555.40it/s] 28%|       | 2769/9788 [00:07<00:12, 554.05it/s] 29%|       | 2833/9788 [00:07<00:12, 553.60it/s] 30%|       | 2897/9788 [00:08<00:12, 553.64it/s] 30%|       | 2961/9788 [00:08<00:12, 555.73it/s] 31%|       | 3025/9788 [00:08<00:12, 554.32it/s] 32%|      | 3089/9788 [00:08<00:12, 555.26it/s] 32%|      | 3153/9788 [00:08<00:11, 555.22it/s] 33%|      | 3217/9788 [00:08<00:11, 562.03it/s] 34%|      | 3281/9788 [00:08<00:11, 564.33it/s] 34%|      | 3345/9788 [00:08<00:11, 566.21it/s] 35%|      | 3409/9788 [00:08<00:11, 566.94it/s] 35%|      | 3473/9788 [00:09<00:11, 568.57it/s] 36%|      | 3537/9788 [00:09<00:10, 569.72it/s] 37%|      | 3601/9788 [00:09<00:10, 569.99it/s] 37%|      | 3665/9788 [00:09<00:10, 569.97it/s] 38%|      | 3729/9788 [00:09<00:10, 573.39it/s] 39%|      | 3793/9788 [00:09<00:10, 574.60it/s] 39%|      | 3857/9788 [00:09<00:10, 575.29it/s] 40%|      | 3921/9788 [00:09<00:10, 575.80it/s] 41%|      | 3985/9788 [00:09<00:10, 576.02it/s] 41%|     | 4049/9788 [00:10<00:09, 578.09it/s] 42%|     | 4113/9788 [00:10<00:09, 577.42it/s] 43%|     | 4177/9788 [00:10<00:09, 577.56it/s] 43%|     | 4241/9788 [00:10<00:09, 578.89it/s] 44%|     | 4305/9788 [00:10<00:09, 579.99it/s] 45%|     | 4369/9788 [00:10<00:09, 582.86it/s] 45%|     | 4433/9788 [00:10<00:09, 584.14it/s] 46%|     | 4497/9788 [00:10<00:09, 583.90it/s] 47%|     | 4561/9788 [00:10<00:08, 583.88it/s] 47%|     | 4625/9788 [00:11<00:08, 586.74it/s] 48%|     | 4689/9788 [00:11<00:08, 587.05it/s] 49%|     | 4753/9788 [00:11<00:08, 588.01it/s] 49%|     | 4817/9788 [00:11<00:08, 589.98it/s] 50%|     | 4881/9788 [00:11<00:08, 591.98it/s] 51%|     | 4945/9788 [00:11<00:08, 594.53it/s] 51%|     | 5009/9788 [00:11<00:08, 596.60it/s] 52%|    | 5073/9788 [00:11<00:07, 601.29it/s] 52%|    | 5137/9788 [00:11<00:07, 604.49it/s] 53%|    | 5201/9788 [00:12<00:07, 608.66it/s] 54%|    | 5265/9788 [00:12<00:07, 613.05it/s] 54%|    | 5329/9788 [00:12<00:07, 614.26it/s] 55%|    | 5393/9788 [00:12<00:07, 614.18it/s] 56%|    | 5457/9788 [00:12<00:07, 612.72it/s] 56%|    | 5521/9788 [00:12<00:06, 613.49it/s] 57%|    | 5585/9788 [00:12<00:06, 612.93it/s] 58%|    | 5649/9788 [00:12<00:06, 615.95it/s] 58%|    | 5713/9788 [00:12<00:06, 619.58it/s] 59%|    | 5777/9788 [00:12<00:06, 619.42it/s] 60%|    | 5841/9788 [00:13<00:06, 624.58it/s] 60%|    | 5905/9788 [00:13<00:06, 626.97it/s] 61%|    | 5977/9788 [00:13<00:05, 654.21it/s] 62%|   | 6043/9788 [00:13<00:05, 654.34it/s] 62%|   | 6109/9788 [00:13<00:05, 654.40it/s] 63%|   | 6175/9788 [00:13<00:05, 654.59it/s] 64%|   | 6241/9788 [00:13<00:05, 614.98it/s] 65%|   | 6314/9788 [00:13<00:05, 647.72it/s] 65%|   | 6385/9788 [00:13<00:05, 626.24it/s] 66%|   | 6464/9788 [00:14<00:04, 671.96it/s] 67%|   | 6532/9788 [00:14<00:05, 640.06it/s] 68%|   | 6609/9788 [00:14<00:04, 641.87it/s] 68%|   | 6689/9788 [00:14<00:04, 653.17it/s] 69%|   | 6769/9788 [00:14<00:04, 664.28it/s] 70%|   | 6849/9788 [00:14<00:04, 672.94it/s] 71%|   | 6929/9788 [00:14<00:04, 679.29it/s] 72%|  | 7009/9788 [00:14<00:04, 686.72it/s] 72%|  | 7089/9788 [00:14<00:03, 693.86it/s] 73%|  | 7169/9788 [00:15<00:03, 699.92it/s] 74%|  | 7249/9788 [00:15<00:03, 701.71it/s] 75%|  | 7329/9788 [00:15<00:03, 704.98it/s] 76%|  | 7409/9788 [00:15<00:03, 708.61it/s] 77%|  | 7489/9788 [00:15<00:03, 715.33it/s] 77%|  | 7569/9788 [00:15<00:03, 720.65it/s] 78%|  | 7649/9788 [00:15<00:02, 723.49it/s] 79%|  | 7729/9788 [00:15<00:02, 728.52it/s] 80%|  | 7809/9788 [00:15<00:02, 732.45it/s] 81%|  | 7889/9788 [00:16<00:02, 735.20it/s] 81%| | 7969/9788 [00:16<00:02, 737.04it/s] 82%| | 8049/9788 [00:16<00:02, 738.98it/s] 83%| | 8129/9788 [00:16<00:02, 742.04it/s] 84%| | 8209/9788 [00:16<00:02, 744.56it/s] 85%| | 8289/9788 [00:16<00:02, 748.94it/s] 86%| | 8369/9788 [00:16<00:01, 753.03it/s] 86%| | 8449/9788 [00:16<00:01, 756.95it/s] 87%| | 8529/9788 [00:16<00:01, 761.26it/s] 88%| | 8609/9788 [00:17<00:01, 761.36it/s] 89%| | 8689/9788 [00:17<00:01, 763.50it/s] 90%| | 8769/9788 [00:17<00:01, 763.18it/s] 90%| | 8849/9788 [00:17<00:01, 764.58it/s] 91%| | 8929/9788 [00:17<00:01, 764.05it/s] 92%|| 9009/9788 [00:17<00:01, 764.12it/s] 93%|| 9089/9788 [00:17<00:00, 766.25it/s] 94%|| 9169/9788 [00:17<00:00, 766.34it/s] 94%|| 9249/9788 [00:17<00:00, 769.06it/s] 95%|| 9329/9788 [00:17<00:00, 772.82it/s] 96%|| 9409/9788 [00:18<00:00, 774.95it/s] 97%|| 9489/9788 [00:18<00:00, 775.63it/s] 98%|| 9569/9788 [00:18<00:00, 775.71it/s] 99%|| 9649/9788 [00:18<00:00, 777.51it/s] 99%|| 9729/9788 [00:18<00:00, 774.52it/s]100%|| 9788/9788 [00:18<00:00, 528.44it/s]
2024-01-16:00:54:34,874 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:00:54:34,874 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:00:54:34,874 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:00:54:34,874 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:00:54:34,874 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:00:54:34,874 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:00:54:34,874 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:00:54:34,874 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
  0%|          | 0/8 [00:00<?, ?it/s] 25%|       | 2/8 [00:00<00:00, 13.24it/s] 50%|     | 4/8 [00:00<00:00, 12.97it/s] 75%|  | 6/8 [00:00<00:00, 12.89it/s]100%|| 8/8 [00:00<00:00, 14.99it/s]
bootstrapping for stddev: perplexity
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:01<01:43,  1.04s/it]  8%|         | 8/100 [00:01<00:10,  9.03it/s] 80%|  | 80/100 [00:01<00:00, 107.71it/s]100%|| 100/100 [00:01<00:00, 60.02it/s]
hf (pretrained=lomahony/pythia-70m-helpful-dpo), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: 16
|    Tasks     |Version|Filter|n-shot|    Metric     |  Value   |   | Stderr  |
|--------------|------:|------|-----:|---------------|---------:|---|---------|
|arc_challenge |      1|none  |     5|acc            |    0.1886|  |   0.0114|
|              |       |none  |     5|acc_norm       |    0.2338|  |   0.0124|
|arc_easy      |      1|none  |     5|acc            |    0.3346|  |   0.0097|
|              |       |none  |     5|acc_norm       |    0.3308|  |   0.0097|
|boolq         |      2|none  |     5|acc            |    0.4028|  |   0.0086|
|hellaswag     |      1|none  |     5|acc            |    0.2617|  |   0.0044|
|              |       |none  |     5|acc_norm       |    0.2648|  |   0.0044|
|lambada_openai|      1|none  |     5|perplexity     |22676.7987|  |1626.4435|
|              |       |none  |     5|acc            |    0.0173|  |   0.0018|
|openbookqa    |      1|none  |     5|acc            |    0.1640|  |   0.0166|
|              |       |none  |     5|acc_norm       |    0.2460|  |   0.0193|
|piqa          |      1|none  |     5|acc            |    0.5528|  |   0.0116|
|              |       |none  |     5|acc_norm       |    0.5462|  |   0.0116|
|sciq          |      1|none  |     5|acc            |    0.3100|  |   0.0146|
|              |       |none  |     5|acc_norm       |    0.4220|  |   0.0156|
|wikitext      |      2|none  |     5|word_perplexity|  547.6920|  |N/A      |
|              |       |none  |     5|byte_perplexity|    3.2518|  |N/A      |
|              |       |none  |     5|bits_per_byte  |    1.7012|  |N/A      |
|winogrande    |      1|none  |     5|acc            |    0.5201|  |   0.0140|

