The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `8`
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-01-16:01:04:35,753 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:01:04:35,753 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:01:04:35,753 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:01:04:35,754 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:01:04:35,754 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:01:04:35,754 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:01:04:35,756 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:01:04:35,756 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:01:04:35,773 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:01:04:35,773 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:01:04:35,778 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:01:04:35,778 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:01:04:35,814 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:01:04:35,814 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:01:04:36,065 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:01:04:36,065 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:01:04:36,291 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:01:04:36,291 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:01:04:36,293 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:01:04:36,296 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:01:04:36,315 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:01:04:36,355 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:01:04:36,356 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:01:04:36,613 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:01:04:40,794 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:01:04:40,795 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:01:04:40,813 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:01:04:40,850 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:01:04:40,966 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:01:04:40,988 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:01:04:41,051 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:01:04:41,315 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:01:04:47,916 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:04:47,941 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:04:48,013 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:04:48,190 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:04:48,255 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:04:48,537 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:01:04:49,262 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:01:04:49,830 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:01:05:41,582 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:05:41,588 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:01:05:41,938 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:05:41,943 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:01:05:42,239 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:05:42,243 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:01:05:42,245 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:05:42,249 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:01:05:42,386 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:05:42,391 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:01:05:43,191 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:05:43,195 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:01:05:44,343 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:05:44,347 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:01:05:44,530 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:05:44,534 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-01-16:01:05:48,423 INFO     [huggingface.py:298] Using 8 devices with data parallelism
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-01-16:01:05:53,173 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:01:05:53,173 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:01:05:53,492 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:01:05:53,492 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:01:05:53,670 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:01:05:53,670 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:01:05:53,733 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:01:05:53,733 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:01:05:54,132 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:01:05:54,132 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:01:05:54,245 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:01:05:54,245 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:01:05:55,221 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:01:05:55,221 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:01:05:55,612 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:01:05:55,612 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:01:06:02,591 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:06:02,591 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:06:02,801 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:06:02,801 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:06:02,906 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:06:02,906 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:06:03,025 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:06:03,025 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:06:03,291 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:06:03,291 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:06:03,336 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:06:03,336 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:06:04,648 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:06:04,648 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:06:04,732 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:06:04,732 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:06:13,574 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:06:13,574 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:06:13,574 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:06:13,574 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:06:13,574 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:01:06:13,574 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:06:13,615 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:06:13,615 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:06:13,615 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:06:13,615 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:06:13,615 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:01:06:13,615 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:06:13,885 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:06:13,885 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:06:13,885 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:06:13,885 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:06:13,885 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:01:06:13,885 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:06:13,935 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:06:13,935 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:06:13,935 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:06:13,935 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:06:13,935 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:01:06:13,935 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:06:13,966 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:06:13,966 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:06:13,966 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:06:13,966 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:06:13,966 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:01:06:13,966 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:06:13,981 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:06:13,981 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:06:13,981 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:06:13,981 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:06:13,981 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:01:06:13,981 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:06:15,573 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:06:15,573 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:06:15,573 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:06:15,573 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:06:15,573 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:01:06:15,573 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:06:15,690 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:06:15,691 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:06:15,691 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:06:15,691 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:06:15,691 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:01:06:15,691 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:06:18,192 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 5
2024-01-16:01:06:18,192 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 5
2024-01-16:01:06:18,192 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 5
2024-01-16:01:06:18,192 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 5
2024-01-16:01:06:18,192 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 5
2024-01-16:01:06:18,192 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 5
2024-01-16:01:06:18,192 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 5
2024-01-16:01:06:18,192 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 5
2024-01-16:01:06:18,192 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 5
2024-01-16:01:06:18,192 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 5
2024-01-16:01:06:18,192 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:06:18,320 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 5
2024-01-16:01:06:18,321 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 5
2024-01-16:01:06:18,321 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 5
2024-01-16:01:06:18,321 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 5
2024-01-16:01:06:18,321 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 5
2024-01-16:01:06:18,321 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 5
2024-01-16:01:06:18,321 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 5
2024-01-16:01:06:18,321 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 5
2024-01-16:01:06:18,321 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 5
2024-01-16:01:06:18,321 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 5
2024-01-16:01:06:18,322 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:06:18,419 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 5
2024-01-16:01:06:18,420 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 5
2024-01-16:01:06:18,420 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 5
2024-01-16:01:06:18,420 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 5
2024-01-16:01:06:18,420 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 5
2024-01-16:01:06:18,420 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 5
2024-01-16:01:06:18,420 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 5
2024-01-16:01:06:18,420 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 5
2024-01-16:01:06:18,420 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 5
2024-01-16:01:06:18,420 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 5
2024-01-16:01:06:18,420 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:06:18,537 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 5
2024-01-16:01:06:18,537 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 5
2024-01-16:01:06:18,537 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 5
2024-01-16:01:06:18,537 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 5
2024-01-16:01:06:18,537 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 5
2024-01-16:01:06:18,537 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 5
2024-01-16:01:06:18,537 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 5
2024-01-16:01:06:18,537 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 5
2024-01-16:01:06:18,537 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 5
2024-01-16:01:06:18,537 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 5
2024-01-16:01:06:18,538 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:06:18,540 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 5
2024-01-16:01:06:18,541 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 5
2024-01-16:01:06:18,541 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 5
2024-01-16:01:06:18,541 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 5
2024-01-16:01:06:18,541 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 5
2024-01-16:01:06:18,541 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 5
2024-01-16:01:06:18,541 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 5
2024-01-16:01:06:18,541 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 5
2024-01-16:01:06:18,541 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 5
2024-01-16:01:06:18,541 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 5
2024-01-16:01:06:18,541 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:06:18,711 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 5
2024-01-16:01:06:18,711 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 5
2024-01-16:01:06:18,711 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 5
2024-01-16:01:06:18,711 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 5
2024-01-16:01:06:18,711 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 5
2024-01-16:01:06:18,711 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 5
2024-01-16:01:06:18,711 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 5
2024-01-16:01:06:18,711 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 5
2024-01-16:01:06:18,711 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 5
2024-01-16:01:06:18,711 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 5
2024-01-16:01:06:18,712 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:06:20,340 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 5
2024-01-16:01:06:20,340 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 5
2024-01-16:01:06:20,340 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 5
2024-01-16:01:06:20,340 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 5
2024-01-16:01:06:20,340 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 5
2024-01-16:01:06:20,341 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 5
2024-01-16:01:06:20,341 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 5
2024-01-16:01:06:20,341 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 5
2024-01-16:01:06:20,341 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 5
2024-01-16:01:06:20,341 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 5
2024-01-16:01:06:20,341 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:06:20,343 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 5
2024-01-16:01:06:20,343 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 5
2024-01-16:01:06:20,343 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 5
2024-01-16:01:06:20,343 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 5
2024-01-16:01:06:20,343 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 5
2024-01-16:01:06:20,343 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 5
2024-01-16:01:06:20,343 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 5
2024-01-16:01:06:20,343 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 5
2024-01-16:01:06:20,343 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 5
2024-01-16:01:06:20,343 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 5
2024-01-16:01:06:20,343 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:06:34,448 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:06:34,448 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:06:34,448 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:06:34,448 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:06:34,448 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:06:34,449 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:06:34,449 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:06:34,449 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:06:38,983 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:06:38,983 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:06:38,983 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:06:38,983 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:06:38,983 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:06:38,984 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:06:38,984 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:06:38,984 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:06:41,127 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:06:41,127 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:06:41,127 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:06:41,127 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:06:41,127 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:06:41,127 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:06:41,128 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:06:41,128 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:06:52,905 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:06:52,905 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:06:52,905 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:06:52,905 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:06:52,905 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:06:52,905 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:06:52,905 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:06:52,905 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:07:01,318 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:07:01,318 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:07:01,318 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:07:01,318 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:07:01,318 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:07:01,318 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:07:01,319 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:07:01,319 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:07:02,105 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:07:02,105 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:07:02,105 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:07:02,105 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:07:02,105 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:07:02,105 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:07:02,105 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:07:02,105 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:07:03,730 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:07:03,730 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:07:03,730 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:07:03,730 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:07:03,730 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:07:03,730 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:07:03,730 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:07:03,730 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:07:04,959 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:07:04,959 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:07:04,959 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:07:04,959 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:07:04,959 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:07:04,959 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:07:04,959 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:07:04,959 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:07:05,058 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:07:05,058 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:07:05,058 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:07:05,058 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:07:05,058 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:07:05,058 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:07:05,058 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:07:05,058 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:07:05,110 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:01:07:05,110 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:01:07:05,110 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:01:07:05,110 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:01:07:05,110 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:01:07:05,110 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:01:07:05,110 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:01:07:05,110 INFO     [evaluator.py:314] Running loglikelihood requests
  0%|          | 0/9788 [00:00<?, ?it/s]  0%|          | 1/9788 [00:01<5:08:15,  1.89s/it]  0%|          | 17/9788 [00:02<14:17, 11.39it/s]   0%|          | 33/9788 [00:02<06:50, 23.75it/s]  1%|          | 49/9788 [00:02<04:17, 37.76it/s]  1%|          | 65/9788 [00:02<03:08, 51.65it/s]  1%|          | 81/9788 [00:02<02:28, 65.26it/s]  1%|          | 97/9788 [00:02<02:03, 78.66it/s]  1%|          | 113/9788 [00:02<01:47, 89.93it/s]  1%|         | 129/9788 [00:02<01:36, 99.79it/s]  1%|         | 145/9788 [00:03<01:29, 108.17it/s]  2%|         | 161/9788 [00:03<01:22, 116.53it/s]  2%|         | 177/9788 [00:03<01:17, 123.36it/s]  2%|         | 193/9788 [00:03<01:13, 131.11it/s]  2%|         | 209/9788 [00:03<01:09, 138.17it/s]  2%|         | 225/9788 [00:03<01:06, 143.86it/s]  2%|         | 241/9788 [00:03<01:04, 147.81it/s]  3%|         | 272/9788 [00:03<00:49, 193.97it/s]  3%|         | 292/9788 [00:03<01:00, 155.86it/s]  3%|         | 321/9788 [00:04<01:00, 155.90it/s]  4%|         | 353/9788 [00:04<00:57, 162.80it/s]  4%|         | 385/9788 [00:04<00:55, 168.18it/s]  4%|         | 417/9788 [00:04<00:53, 173.63it/s]  5%|         | 449/9788 [00:04<00:52, 177.74it/s]  5%|         | 481/9788 [00:05<00:50, 182.69it/s]  5%|         | 513/9788 [00:05<00:49, 186.01it/s]  6%|         | 545/9788 [00:05<00:48, 188.95it/s]  6%|         | 577/9788 [00:05<00:47, 195.66it/s]  6%|         | 609/9788 [00:05<00:45, 200.67it/s]  7%|         | 641/9788 [00:05<00:45, 202.67it/s]  7%|         | 673/9788 [00:05<00:44, 206.91it/s]  7%|         | 705/9788 [00:06<00:43, 209.55it/s]  8%|         | 737/9788 [00:06<00:42, 214.25it/s]  8%|         | 769/9788 [00:06<00:41, 216.83it/s]  8%|         | 801/9788 [00:06<00:40, 222.39it/s]  9%|         | 833/9788 [00:06<00:39, 224.57it/s]  9%|         | 865/9788 [00:06<00:39, 228.01it/s]  9%|         | 897/9788 [00:06<00:38, 232.90it/s]  9%|         | 929/9788 [00:07<00:36, 239.97it/s] 10%|         | 961/9788 [00:07<00:36, 243.39it/s] 10%|         | 993/9788 [00:07<00:35, 246.91it/s] 10%|         | 1025/9788 [00:07<00:34, 252.39it/s] 11%|         | 1057/9788 [00:07<00:33, 259.55it/s] 11%|         | 1089/9788 [00:07<00:33, 263.15it/s] 11%|        | 1121/9788 [00:07<00:32, 268.51it/s] 12%|        | 1153/9788 [00:07<00:31, 270.41it/s] 12%|        | 1185/9788 [00:07<00:31, 274.94it/s] 12%|        | 1217/9788 [00:08<00:30, 276.77it/s] 13%|        | 1249/9788 [00:08<00:30, 280.94it/s] 13%|        | 1281/9788 [00:08<00:30, 282.26it/s] 13%|        | 1313/9788 [00:08<00:29, 283.50it/s] 14%|        | 1345/9788 [00:08<00:29, 287.37it/s] 14%|        | 1377/9788 [00:08<00:29, 286.35it/s] 14%|        | 1409/9788 [00:08<00:29, 287.66it/s] 15%|        | 1441/9788 [00:08<00:29, 286.81it/s] 15%|        | 1473/9788 [00:08<00:28, 287.82it/s] 15%|        | 1505/9788 [00:09<00:28, 288.68it/s] 16%|        | 1537/9788 [00:09<00:28, 292.14it/s] 16%|        | 1569/9788 [00:09<00:28, 293.52it/s] 16%|        | 1601/9788 [00:09<00:27, 293.95it/s] 17%|        | 1633/9788 [00:09<00:27, 299.04it/s] 17%|        | 1665/9788 [00:09<00:26, 301.66it/s] 17%|        | 1697/9788 [00:09<00:26, 304.14it/s] 18%|        | 1729/9788 [00:09<00:26, 306.03it/s] 18%|        | 1761/9788 [00:09<00:25, 309.85it/s] 18%|        | 1793/9788 [00:10<00:25, 310.38it/s] 19%|        | 1825/9788 [00:10<00:25, 310.68it/s] 19%|        | 1857/9788 [00:10<00:25, 310.98it/s] 19%|        | 1891/9788 [00:10<00:24, 319.48it/s] 20%|        | 1923/9788 [00:10<00:24, 318.07it/s] 20%|        | 1955/9788 [00:10<00:24, 316.67it/s] 20%|        | 1987/9788 [00:10<00:24, 315.48it/s] 21%|        | 2019/9788 [00:10<00:24, 313.64it/s] 21%|        | 2055/9788 [00:10<00:23, 327.19it/s] 21%|       | 2088/9788 [00:10<00:23, 325.67it/s] 22%|       | 2121/9788 [00:11<00:23, 325.16it/s] 22%|       | 2154/9788 [00:11<00:23, 324.82it/s] 22%|       | 2187/9788 [00:11<00:23, 325.84it/s] 23%|       | 2220/9788 [00:11<00:23, 324.97it/s] 23%|       | 2257/9788 [00:11<00:25, 298.10it/s] 23%|       | 2289/9788 [00:11<00:24, 303.30it/s] 24%|       | 2328/9788 [00:11<00:22, 327.49it/s] 24%|       | 2364/9788 [00:11<00:22, 336.70it/s] 25%|       | 2400/9788 [00:11<00:21, 343.40it/s] 25%|       | 2435/9788 [00:12<00:24, 305.99it/s] 25%|       | 2475/9788 [00:12<00:22, 331.32it/s] 26%|       | 2511/9788 [00:12<00:21, 339.16it/s] 26%|       | 2546/9788 [00:12<00:23, 303.48it/s] 26%|       | 2591/9788 [00:12<00:21, 342.18it/s] 27%|       | 2627/9788 [00:12<00:23, 310.77it/s] 27%|       | 2673/9788 [00:12<00:22, 313.67it/s] 28%|       | 2721/9788 [00:12<00:22, 319.19it/s] 28%|       | 2769/9788 [00:13<00:21, 322.70it/s] 29%|       | 2811/9788 [00:13<00:20, 345.86it/s] 29%|       | 2849/9788 [00:13<00:21, 320.05it/s] 30%|       | 2894/9788 [00:13<00:19, 352.00it/s] 30%|       | 2931/9788 [00:13<00:20, 327.26it/s] 30%|       | 2975/9788 [00:13<00:19, 355.93it/s] 31%|       | 3012/9788 [00:13<00:20, 322.71it/s] 31%|       | 3057/9788 [00:13<00:21, 319.56it/s] 32%|      | 3105/9788 [00:14<00:20, 322.75it/s] 32%|      | 3153/9788 [00:14<00:20, 327.32it/s] 33%|      | 3201/9788 [00:14<00:19, 336.59it/s] 33%|      | 3249/9788 [00:14<00:19, 342.31it/s] 34%|      | 3297/9788 [00:14<00:18, 344.47it/s] 34%|      | 3345/9788 [00:14<00:18, 345.56it/s] 35%|      | 3393/9788 [00:14<00:18, 346.16it/s] 35%|      | 3441/9788 [00:15<00:18, 346.63it/s] 36%|      | 3489/9788 [00:15<00:17, 350.75it/s] 36%|      | 3537/9788 [00:15<00:17, 350.32it/s] 37%|      | 3585/9788 [00:15<00:17, 351.13it/s] 37%|      | 3633/9788 [00:15<00:17, 351.56it/s] 38%|      | 3681/9788 [00:15<00:17, 352.87it/s] 38%|      | 3729/9788 [00:15<00:16, 358.00it/s] 39%|      | 3777/9788 [00:15<00:16, 359.27it/s] 39%|      | 3825/9788 [00:16<00:16, 359.11it/s] 40%|      | 3873/9788 [00:16<00:16, 358.15it/s] 40%|      | 3921/9788 [00:16<00:16, 358.52it/s] 41%|      | 3969/9788 [00:16<00:16, 358.33it/s] 41%|      | 4017/9788 [00:16<00:16, 357.95it/s] 42%|     | 4065/9788 [00:16<00:15, 362.47it/s] 42%|     | 4113/9788 [00:16<00:15, 361.57it/s] 43%|     | 4161/9788 [00:17<00:15, 361.26it/s] 43%|     | 4209/9788 [00:17<00:15, 361.22it/s] 43%|     | 4257/9788 [00:17<00:15, 361.61it/s] 44%|     | 4305/9788 [00:17<00:15, 364.27it/s] 44%|     | 4353/9788 [00:17<00:14, 368.13it/s] 45%|     | 4401/9788 [00:17<00:14, 368.01it/s] 45%|     | 4449/9788 [00:17<00:14, 366.75it/s] 46%|     | 4497/9788 [00:17<00:14, 367.38it/s] 46%|     | 4545/9788 [00:18<00:14, 366.28it/s] 47%|     | 4593/9788 [00:18<00:14, 370.75it/s] 47%|     | 4641/9788 [00:18<00:13, 369.53it/s] 48%|     | 4689/9788 [00:18<00:13, 367.79it/s] 48%|     | 4737/9788 [00:18<00:13, 367.84it/s] 49%|     | 4785/9788 [00:18<00:13, 367.33it/s] 49%|     | 4833/9788 [00:18<00:13, 371.44it/s] 50%|     | 4881/9788 [00:19<00:13, 370.55it/s] 50%|     | 4929/9788 [00:19<00:13, 370.02it/s] 51%|     | 4977/9788 [00:19<00:12, 370.55it/s] 51%|    | 5025/9788 [00:19<00:12, 371.01it/s] 52%|    | 5073/9788 [00:19<00:12, 374.91it/s] 52%|    | 5121/9788 [00:19<00:12, 373.99it/s] 53%|    | 5169/9788 [00:19<00:12, 374.18it/s] 53%|    | 5217/9788 [00:19<00:12, 375.06it/s] 54%|    | 5265/9788 [00:20<00:11, 378.27it/s] 54%|    | 5313/9788 [00:20<00:11, 382.04it/s] 55%|    | 5361/9788 [00:20<00:11, 385.54it/s] 55%|    | 5409/9788 [00:20<00:11, 388.27it/s] 56%|    | 5457/9788 [00:20<00:11, 390.10it/s] 56%|    | 5505/9788 [00:20<00:10, 392.86it/s] 57%|    | 5553/9788 [00:20<00:10, 392.72it/s] 57%|    | 5601/9788 [00:20<00:10, 393.41it/s] 58%|    | 5649/9788 [00:21<00:10, 394.75it/s] 58%|    | 5697/9788 [00:21<00:10, 394.70it/s] 59%|    | 5745/9788 [00:21<00:10, 395.50it/s] 59%|    | 5793/9788 [00:21<00:10, 396.78it/s] 60%|    | 5841/9788 [00:21<00:09, 398.21it/s] 60%|    | 5889/9788 [00:21<00:09, 399.35it/s] 61%|    | 5937/9788 [00:21<00:09, 402.48it/s] 61%|    | 5985/9788 [00:21<00:09, 405.69it/s] 62%|   | 6033/9788 [00:21<00:09, 406.84it/s] 62%|   | 6081/9788 [00:22<00:09, 410.75it/s] 63%|   | 6129/9788 [00:22<00:08, 412.12it/s] 63%|   | 6177/9788 [00:22<00:08, 412.67it/s] 64%|   | 6225/9788 [00:22<00:08, 415.50it/s] 64%|   | 6273/9788 [00:22<00:08, 416.06it/s] 65%|   | 6321/9788 [00:22<00:08, 415.80it/s] 65%|   | 6369/9788 [00:22<00:08, 417.95it/s] 66%|   | 6417/9788 [00:22<00:08, 417.19it/s] 66%|   | 6465/9788 [00:22<00:07, 423.54it/s] 67%|   | 6513/9788 [00:23<00:07, 427.75it/s] 67%|   | 6561/9788 [00:23<00:07, 431.38it/s] 68%|   | 6609/9788 [00:23<00:07, 436.07it/s] 68%|   | 6657/9788 [00:23<00:07, 439.31it/s] 69%|   | 6705/9788 [00:23<00:06, 442.09it/s] 69%|   | 6753/9788 [00:23<00:06, 445.46it/s] 69%|   | 6801/9788 [00:23<00:06, 449.57it/s] 70%|   | 6849/9788 [00:23<00:06, 454.40it/s] 70%|   | 6897/9788 [00:23<00:06, 459.97it/s] 71%|   | 6945/9788 [00:24<00:06, 465.68it/s] 71%|  | 6997/9788 [00:24<00:05, 481.60it/s] 72%|  | 7053/9788 [00:24<00:05, 504.75it/s] 73%|  | 7105/9788 [00:24<00:05, 471.54it/s] 73%|  | 7169/9788 [00:24<00:05, 492.49it/s] 74%|  | 7233/9788 [00:24<00:05, 510.50it/s] 75%|  | 7297/9788 [00:24<00:04, 523.63it/s] 75%|  | 7361/9788 [00:24<00:04, 535.61it/s] 76%|  | 7425/9788 [00:24<00:04, 546.32it/s] 77%|  | 7489/9788 [00:25<00:04, 553.97it/s] 77%|  | 7553/9788 [00:25<00:03, 561.05it/s] 78%|  | 7617/9788 [00:25<00:03, 568.08it/s] 78%|  | 7681/9788 [00:25<00:03, 573.60it/s] 79%|  | 7745/9788 [00:25<00:03, 577.63it/s] 80%|  | 7809/9788 [00:25<00:03, 581.98it/s] 80%|  | 7873/9788 [00:25<00:03, 585.18it/s] 81%|  | 7937/9788 [00:25<00:03, 586.89it/s] 82%| | 8001/9788 [00:25<00:03, 590.12it/s] 82%| | 8065/9788 [00:26<00:02, 591.97it/s] 83%| | 8129/9788 [00:26<00:02, 597.12it/s] 84%| | 8193/9788 [00:26<00:02, 599.74it/s] 84%| | 8257/9788 [00:26<00:02, 603.03it/s] 85%| | 8321/9788 [00:26<00:02, 603.62it/s] 86%| | 8385/9788 [00:26<00:02, 604.60it/s] 86%| | 8449/9788 [00:26<00:02, 605.13it/s] 87%| | 8513/9788 [00:26<00:02, 605.86it/s] 88%| | 8577/9788 [00:26<00:02, 604.89it/s] 88%| | 8641/9788 [00:26<00:01, 606.11it/s] 89%| | 8705/9788 [00:27<00:01, 607.47it/s] 90%| | 8769/9788 [00:27<00:01, 608.15it/s] 90%| | 8833/9788 [00:27<00:01, 610.54it/s] 91%| | 8897/9788 [00:27<00:01, 611.70it/s] 92%|| 8961/9788 [00:27<00:01, 613.96it/s] 92%|| 9025/9788 [00:27<00:01, 618.34it/s] 93%|| 9089/9788 [00:27<00:01, 619.60it/s] 94%|| 9153/9788 [00:27<00:01, 618.63it/s] 94%|| 9217/9788 [00:27<00:00, 618.69it/s] 95%|| 9281/9788 [00:28<00:00, 619.79it/s] 95%|| 9345/9788 [00:28<00:00, 621.79it/s] 96%|| 9409/9788 [00:28<00:00, 623.57it/s] 97%|| 9473/9788 [00:28<00:00, 624.90it/s] 97%|| 9537/9788 [00:28<00:00, 624.98it/s] 98%|| 9601/9788 [00:28<00:00, 625.78it/s] 99%|| 9665/9788 [00:28<00:00, 628.75it/s]100%|| 9741/9788 [00:28<00:00, 667.62it/s]100%|| 9788/9788 [00:28<00:00, 339.83it/s]
2024-01-16:01:07:54,358 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:01:07:54,358 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:01:07:54,358 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:01:07:54,358 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:01:07:54,358 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:01:07:54,358 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:01:07:54,358 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:01:07:54,358 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
  0%|          | 0/8 [00:00<?, ?it/s] 25%|       | 2/8 [00:00<00:00,  7.15it/s] 38%|      | 3/8 [00:00<00:00,  6.80it/s] 50%|     | 4/8 [00:00<00:00,  7.03it/s] 62%|   | 5/8 [00:00<00:00,  6.69it/s] 75%|  | 6/8 [00:00<00:00,  6.93it/s]100%|| 8/8 [00:00<00:00,  9.46it/s]100%|| 8/8 [00:00<00:00,  8.02it/s]
bootstrapping for stddev: perplexity
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:01<01:50,  1.12s/it] 14%|        | 14/100 [00:01<00:05, 14.61it/s] 98%|| 98/100 [00:01<00:00, 95.48it/s]100%|| 100/100 [00:01<00:00, 62.15it/s]
hf (pretrained=lomahony/pythia-160m-helpful-sft), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: 16
|    Tasks     |Version|Filter|n-shot|    Metric     |  Value  |   |Stderr |
|--------------|------:|------|-----:|---------------|--------:|---|-------|
|arc_challenge |      1|none  |     5|acc            |   0.2022|  | 0.0117|
|              |       |none  |     5|acc_norm       |   0.2270|  | 0.0122|
|arc_easy      |      1|none  |     5|acc            |   0.3733|  | 0.0099|
|              |       |none  |     5|acc_norm       |   0.3746|  | 0.0099|
|boolq         |      2|none  |     5|acc            |   0.5413|  | 0.0087|
|hellaswag     |      1|none  |     5|acc            |   0.2770|  | 0.0045|
|              |       |none  |     5|acc_norm       |   0.2853|  | 0.0045|
|lambada_openai|      1|none  |     5|perplexity     |1644.8526|  |87.8870|
|              |       |none  |     5|acc            |   0.0491|  | 0.0030|
|openbookqa    |      1|none  |     5|acc            |   0.1400|  | 0.0155|
|              |       |none  |     5|acc_norm       |   0.2200|  | 0.0185|
|piqa          |      1|none  |     5|acc            |   0.5892|  | 0.0115|
|              |       |none  |     5|acc_norm       |   0.5854|  | 0.0115|
|sciq          |      1|none  |     5|acc            |   0.5100|  | 0.0158|
|              |       |none  |     5|acc_norm       |   0.6020|  | 0.0155|
|wikitext      |      2|none  |     5|word_perplexity|  87.3261|  |N/A    |
|              |       |none  |     5|byte_perplexity|   2.3068|  |N/A    |
|              |       |none  |     5|bits_per_byte  |   1.2059|  |N/A    |
|winogrande    |      1|none  |     5|acc            |   0.5178|  | 0.0140|

