The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `8`
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-01-16:01:08:22,965 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:01:08:22,965 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:01:08:22,965 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:01:08:22,965 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:01:08:22,985 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:01:08:22,985 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:01:08:23,049 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:01:08:23,049 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:01:08:23,071 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:01:08:23,071 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:01:08:23,108 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:01:08:23,108 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:01:08:23,115 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:01:08:23,115 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:01:08:23,116 INFO     [utils.py:145] Note: detected 96 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-01-16:01:08:23,116 INFO     [utils.py:148] Note: NumExpr detected 96 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-01-16:01:08:23,517 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:01:08:23,518 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:01:08:23,522 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:01:08:23,563 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:01:08:23,634 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:01:08:23,645 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:01:08:23,654 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:01:08:23,658 INFO     [config.py:58] PyTorch version 2.1.2 available.
2024-01-16:01:08:28,076 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:01:08:28,077 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:01:08:28,083 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:01:08:28,103 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:01:08:28,118 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:01:08:28,136 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:01:08:28,173 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:01:08:28,319 INFO     [__main__.py:156] Verbosity set to INFO
2024-01-16:01:08:35,088 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:08:35,089 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:08:35,222 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:08:35,265 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:08:35,421 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:08:35,765 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:01:08:36,374 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:01:08:36,670 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:01:09:28,402 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:09:28,408 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:01:09:28,775 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:09:28,779 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:01:09:28,782 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:09:28,787 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:01:09:29,644 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:09:29,646 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:09:29,649 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:01:09:29,650 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:01:09:29,809 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:09:29,813 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
config.json:   0%|          | 0.00/721 [00:00<?, ?B/s]config.json: 100%|██████████| 721/721 [00:00<00:00, 3.80MB/s]
2024-01-16:01:09:31,073 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:09:31,077 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
2024-01-16:01:09:31,215 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.
2024-01-16:01:09:31,219 INFO     [__main__.py:229] Selected Tasks: ['arc_challenge', 'arc_easy', 'boolq', 'hellaswag', 'lambada_openai', 'openbookqa', 'piqa', 'sciq', 'wikitext', 'winogrande']
pytorch_model.bin:   0%|          | 0.00/700M [00:00<?, ?B/s]pytorch_model.bin:   1%|▏         | 10.5M/700M [00:00<00:08, 81.6MB/s]pytorch_model.bin:   3%|▎         | 21.0M/700M [00:00<00:08, 84.2MB/s]pytorch_model.bin:   4%|▍         | 31.5M/700M [00:00<00:07, 84.3MB/s]pytorch_model.bin:   6%|▌         | 41.9M/700M [00:00<00:07, 86.6MB/s]pytorch_model.bin:   7%|▋         | 52.4M/700M [00:00<00:07, 86.5MB/s]pytorch_model.bin:   9%|▉         | 62.9M/700M [00:00<00:07, 86.2MB/s]pytorch_model.bin:  10%|█         | 73.4M/700M [00:00<00:07, 85.6MB/s]pytorch_model.bin:  12%|█▏        | 83.9M/700M [00:00<00:07, 85.4MB/s]pytorch_model.bin:  13%|█▎        | 94.4M/700M [00:01<00:07, 84.4MB/s]pytorch_model.bin:  15%|█▍        | 105M/700M [00:01<00:06, 85.5MB/s] pytorch_model.bin:  16%|█▋        | 115M/700M [00:01<00:06, 85.8MB/s]pytorch_model.bin:  18%|█▊        | 126M/700M [00:01<00:06, 85.5MB/s]pytorch_model.bin:  19%|█▉        | 136M/700M [00:01<00:06, 85.9MB/s]pytorch_model.bin:  21%|██        | 147M/700M [00:01<00:06, 84.9MB/s]pytorch_model.bin:  22%|██▏       | 157M/700M [00:01<00:06, 84.9MB/s]pytorch_model.bin:  24%|██▍       | 168M/700M [00:01<00:06, 85.0MB/s]pytorch_model.bin:  25%|██▌       | 178M/700M [00:02<00:06, 84.6MB/s]pytorch_model.bin:  27%|██▋       | 189M/700M [00:02<00:06, 84.6MB/s]pytorch_model.bin:  28%|██▊       | 199M/700M [00:02<00:05, 84.8MB/s]pytorch_model.bin:  30%|██▉       | 210M/700M [00:02<00:05, 85.1MB/s]pytorch_model.bin:  31%|███▏      | 220M/700M [00:02<00:05, 85.0MB/s]pytorch_model.bin:  33%|███▎      | 231M/700M [00:02<00:05, 83.4MB/s]pytorch_model.bin:  34%|███▍      | 241M/700M [00:02<00:05, 83.7MB/s]pytorch_model.bin:  36%|███▌      | 252M/700M [00:02<00:05, 84.1MB/s]pytorch_model.bin:  37%|███▋      | 262M/700M [00:03<00:05, 84.0MB/s]pytorch_model.bin:  39%|███▉      | 273M/700M [00:03<00:05, 84.3MB/s]pytorch_model.bin:  40%|████      | 283M/700M [00:03<00:04, 84.9MB/s]pytorch_model.bin:  42%|████▏     | 294M/700M [00:03<00:04, 84.7MB/s]pytorch_model.bin:  43%|████▎     | 304M/700M [00:03<00:04, 84.5MB/s]pytorch_model.bin:  45%|████▍     | 315M/700M [00:03<00:04, 84.3MB/s]pytorch_model.bin:  46%|████▋     | 325M/700M [00:03<00:04, 82.4MB/s]pytorch_model.bin:  48%|████▊     | 336M/700M [00:03<00:04, 84.2MB/s]pytorch_model.bin:  49%|████▉     | 346M/700M [00:04<00:04, 84.3MB/s]pytorch_model.bin:  51%|█████     | 357M/700M [00:04<00:03, 85.8MB/s]pytorch_model.bin:  52%|█████▏    | 367M/700M [00:04<00:03, 85.2MB/s]pytorch_model.bin:  54%|█████▍    | 377M/700M [00:04<00:03, 85.4MB/s]pytorch_model.bin:  55%|█████▌    | 388M/700M [00:04<00:03, 85.6MB/s]pytorch_model.bin:  57%|█████▋    | 398M/700M [00:04<00:03, 85.3MB/s]pytorch_model.bin:  58%|█████▊    | 409M/700M [00:04<00:03, 85.7MB/s]pytorch_model.bin:  60%|█████▉    | 419M/700M [00:04<00:03, 85.7MB/s]pytorch_model.bin:  61%|██████▏   | 430M/700M [00:05<00:03, 85.3MB/s]pytorch_model.bin:  63%|██████▎   | 440M/700M [00:05<00:03, 84.9MB/s]pytorch_model.bin:  64%|██████▍   | 451M/700M [00:05<00:02, 85.0MB/s]pytorch_model.bin:  66%|██████▌   | 461M/700M [00:05<00:02, 85.3MB/s]pytorch_model.bin:  67%|██████▋   | 472M/700M [00:05<00:02, 85.0MB/s]pytorch_model.bin:  69%|██████▉   | 482M/700M [00:05<00:02, 84.4MB/s]pytorch_model.bin:  70%|███████   | 493M/700M [00:05<00:02, 85.3MB/s]pytorch_model.bin:  72%|███████▏  | 503M/700M [00:05<00:02, 85.7MB/s]pytorch_model.bin:  73%|███████▎  | 514M/700M [00:06<00:02, 85.8MB/s]pytorch_model.bin:  75%|███████▍  | 524M/700M [00:06<00:02, 85.5MB/s]pytorch_model.bin:  76%|███████▋  | 535M/700M [00:06<00:01, 85.6MB/s]pytorch_model.bin:  78%|███████▊  | 545M/700M [00:06<00:01, 80.9MB/s]pytorch_model.bin:  79%|███████▉  | 556M/700M [00:06<00:01, 85.7MB/s]pytorch_model.bin:  81%|████████  | 566M/700M [00:06<00:01, 85.7MB/s]pytorch_model.bin:  82%|████████▏ | 577M/700M [00:06<00:01, 81.1MB/s]pytorch_model.bin:  84%|████████▍ | 587M/700M [00:06<00:01, 84.7MB/s]pytorch_model.bin:  85%|████████▌ | 598M/700M [00:07<00:01, 86.5MB/s]pytorch_model.bin:  87%|████████▋ | 608M/700M [00:07<00:01, 86.5MB/s]pytorch_model.bin:  88%|████████▊ | 619M/700M [00:07<00:00, 85.8MB/s]pytorch_model.bin:  90%|████████▉ | 629M/700M [00:07<00:00, 85.8MB/s]pytorch_model.bin:  91%|█████████▏| 640M/700M [00:07<00:00, 85.3MB/s]pytorch_model.bin:  93%|█████████▎| 650M/700M [00:07<00:00, 85.3MB/s]pytorch_model.bin:  94%|█████████▍| 661M/700M [00:07<00:00, 85.9MB/s]pytorch_model.bin:  96%|█████████▌| 671M/700M [00:07<00:00, 85.6MB/s]pytorch_model.bin:  97%|█████████▋| 682M/700M [00:08<00:00, 85.9MB/s]pytorch_model.bin:  99%|█████████▉| 692M/700M [00:08<00:00, 84.7MB/s]pytorch_model.bin: 100%|██████████| 700M/700M [00:08<00:00, 84.9MB/s]
generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]generation_config.json: 100%|██████████| 111/111 [00:00<00:00, 837kB/s]
tokenizer_config.json:   0%|          | 0.00/4.82k [00:00<?, ?B/s]tokenizer_config.json: 100%|██████████| 4.82k/4.82k [00:00<00:00, 43.5MB/s]
tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]tokenizer.json: 100%|██████████| 2.11M/2.11M [00:00<00:00, 6.28MB/s]tokenizer.json: 100%|██████████| 2.11M/2.11M [00:00<00:00, 6.27MB/s]
special_tokens_map.json:   0%|          | 0.00/153 [00:00<?, ?B/s]special_tokens_map.json: 100%|██████████| 153/153 [00:00<00:00, 1.26MB/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-01-16:01:09:44,530 INFO     [huggingface.py:298] Using 8 devices with data parallelism
2024-01-16:01:09:50,910 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:01:09:50,910 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:01:09:51,186 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:01:09:51,186 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:01:09:51,191 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:01:09:51,191 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:01:09:51,196 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:01:09:51,196 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:01:09:51,210 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:01:09:51,210 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2024-01-16:01:09:51,419 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:01:09:51,419 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:01:09:51,957 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:01:09:51,957 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:01:09:52,022 WARNING  [task.py:600] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
2024-01-16:01:09:52,022 WARNING  [task.py:612] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/admin/home-laura/venvs/venv-lm-evaluation-harness/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-01-16:01:10:00,198 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:10:00,198 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:10:00,263 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:10:00,263 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:10:00,360 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:10:00,360 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:10:00,632 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:10:00,632 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:10:01,229 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:10:01,230 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:10:01,326 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:10:01,326 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:10:01,333 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:10:01,333 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:10:01,822 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:10:01,822 WARNING  [task.py:284] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-01-16:01:10:10,976 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:10:10,977 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:10:10,977 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:10:10,977 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:10:10,977 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:01:10:10,977 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:10:11,290 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:10:11,290 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:10:11,290 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:10:11,290 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:10:11,290 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:01:10:11,290 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:10:11,732 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:10:11,732 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:10:11,732 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:10:11,732 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:10:11,732 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:01:10:11,732 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:10:12,115 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:10:12,115 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:10:12,115 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:10:12,115 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:10:12,115 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:01:10:12,115 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:10:12,431 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:10:12,431 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:10:12,431 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:10:12,431 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:10:12,431 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:01:10:12,431 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:10:13,097 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:10:13,097 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:10:13,097 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:10:13,097 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:10:13,097 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:01:10:13,097 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:10:13,180 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:10:13,180 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:10:13,180 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:10:13,180 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:10:13,180 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:01:10:13,180 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:10:13,316 WARNING  [task.py:600] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:10:13,316 WARNING  [task.py:612] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:10:13,316 WARNING  [task.py:600] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-01-16:01:10:13,316 WARNING  [task.py:612] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:10:13,316 WARNING  [task.py:600] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-01-16:01:10:13,316 WARNING  [task.py:612] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2024-01-16:01:10:15,481 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:01:10:15,481 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:01:10:15,481 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:01:10:15,481 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:01:10:15,481 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:01:10:15,481 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:01:10:15,481 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:01:10:15,481 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:01:10:15,481 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:01:10:15,481 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:01:10:15,481 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:10:15,986 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:01:10:15,986 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:01:10:15,986 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:01:10:15,986 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:01:10:15,987 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:01:10:15,987 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:01:10:15,987 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:01:10:15,987 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:01:10:15,987 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:01:10:15,987 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:01:10:15,987 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:10:16,500 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:01:10:16,501 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:01:10:16,501 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:01:10:16,501 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:01:10:16,501 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:01:10:16,501 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:01:10:16,501 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:01:10:16,501 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:01:10:16,501 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:01:10:16,501 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:01:10:16,501 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:10:16,818 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:01:10:16,818 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:01:10:16,818 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:01:10:16,818 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:01:10:16,818 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:01:10:16,818 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:01:10:16,818 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:01:10:16,818 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:01:10:16,818 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:01:10:16,818 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:01:10:16,818 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:10:16,956 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:01:10:16,956 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:01:10:16,956 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:01:10:16,956 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:01:10:16,956 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:01:10:16,956 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:01:10:16,956 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:01:10:16,956 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:01:10:16,956 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:01:10:16,956 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:01:10:16,956 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:10:17,900 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:01:10:17,901 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:01:10:17,901 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:01:10:17,901 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:01:10:17,901 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:01:10:17,901 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:01:10:17,901 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:01:10:17,901 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:01:10:17,901 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:01:10:17,901 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:01:10:17,901 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:10:17,920 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:01:10:17,920 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:01:10:17,920 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:01:10:17,920 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:01:10:17,920 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:01:10:17,921 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:01:10:17,921 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:01:10:17,921 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:01:10:17,921 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:01:10:17,921 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:01:10:17,921 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:10:18,038 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_challenge from None to 0
2024-01-16:01:10:18,038 WARNING  [evaluator.py:141] Overwriting default num_fewshot of arc_easy from None to 0
2024-01-16:01:10:18,038 WARNING  [evaluator.py:141] Overwriting default num_fewshot of boolq from None to 0
2024-01-16:01:10:18,038 WARNING  [evaluator.py:141] Overwriting default num_fewshot of hellaswag from None to 0
2024-01-16:01:10:18,038 WARNING  [evaluator.py:141] Overwriting default num_fewshot of lambada_openai from None to 0
2024-01-16:01:10:18,038 WARNING  [evaluator.py:141] Overwriting default num_fewshot of openbookqa from None to 0
2024-01-16:01:10:18,038 WARNING  [evaluator.py:141] Overwriting default num_fewshot of piqa from None to 0
2024-01-16:01:10:18,038 WARNING  [evaluator.py:141] Overwriting default num_fewshot of sciq from None to 0
2024-01-16:01:10:18,038 WARNING  [evaluator.py:141] Overwriting default num_fewshot of wikitext from None to 0
2024-01-16:01:10:18,038 WARNING  [evaluator.py:141] Overwriting default num_fewshot of winogrande from None to 0
2024-01-16:01:10:18,039 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:10:29,783 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:10:29,783 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:10:29,783 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:10:29,783 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:10:29,783 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:10:29,783 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:10:29,783 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:10:29,783 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:10:30,210 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:10:30,210 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:10:30,210 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:10:30,210 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:10:30,210 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:10:30,210 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:10:30,210 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:10:30,210 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:10:30,533 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:10:30,533 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:10:30,533 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:10:30,533 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:10:30,533 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:10:30,533 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:10:30,533 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:10:30,534 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:10:31,968 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:10:31,968 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:10:31,968 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:10:31,968 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:10:31,968 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:10:31,968 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:10:31,968 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:10:31,969 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:10:33,080 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:10:33,080 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:10:33,080 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:10:33,080 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:10:33,080 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:10:33,081 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:10:33,081 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:10:33,081 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:10:33,136 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:10:33,136 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:10:33,136 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:10:33,136 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:10:33,136 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:10:33,136 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:10:33,136 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:10:33,136 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:10:33,400 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:10:33,400 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:10:33,400 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:10:33,400 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:10:33,400 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:10:33,400 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:10:33,400 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:10:33,400 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:10:33,590 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:10:33,590 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:10:33,590 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:10:33,590 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:10:33,590 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:10:33,590 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:10:33,590 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:10:33,590 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:10:33,610 INFO     [task.py:337] Building contexts for task on rank 3...
2024-01-16:01:10:33,610 INFO     [task.py:337] Building contexts for task on rank 2...
2024-01-16:01:10:33,610 INFO     [task.py:337] Building contexts for task on rank 5...
2024-01-16:01:10:33,610 INFO     [task.py:337] Building contexts for task on rank 6...
2024-01-16:01:10:33,610 INFO     [task.py:337] Building contexts for task on rank 4...
2024-01-16:01:10:33,610 INFO     [task.py:337] Building contexts for task on rank 1...
2024-01-16:01:10:33,610 INFO     [task.py:337] Building contexts for task on rank 7...
2024-01-16:01:10:33,610 INFO     [task.py:337] Building contexts for task on rank 0...
2024-01-16:01:10:33,649 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:01:10:33,649 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:01:10:33,649 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:01:10:33,649 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:01:10:33,649 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:01:10:33,649 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:01:10:33,649 INFO     [evaluator.py:314] Running loglikelihood requests
2024-01-16:01:10:33,649 INFO     [evaluator.py:314] Running loglikelihood requests
  0%|          | 0/9788 [00:00<?, ?it/s]  0%|          | 1/9788 [00:01<4:23:34,  1.62s/it]  1%|          | 49/9788 [00:01<04:07, 39.35it/s]   1%|          | 113/9788 [00:01<01:37, 99.71it/s]  2%|▏         | 177/9788 [00:01<00:57, 166.42it/s]  2%|▏         | 241/9788 [00:02<00:40, 236.04it/s]  3%|▎         | 305/9788 [00:02<00:31, 303.31it/s]  4%|▍         | 369/9788 [00:02<00:25, 366.73it/s]  4%|▍         | 433/9788 [00:02<00:22, 423.20it/s]  5%|▌         | 497/9788 [00:02<00:19, 471.39it/s]  6%|▌         | 561/9788 [00:02<00:18, 511.28it/s]  6%|▋         | 625/9788 [00:02<00:16, 544.39it/s]  7%|▋         | 694/9788 [00:02<00:15, 584.06it/s]  8%|▊         | 763/9788 [00:02<00:14, 613.71it/s]  8%|▊         | 829/9788 [00:02<00:14, 622.21it/s]  9%|▉         | 897/9788 [00:03<00:14, 600.90it/s] 10%|▉         | 961/9788 [00:03<00:14, 610.82it/s] 10%|█         | 1026/9788 [00:03<00:14, 621.95it/s] 11%|█         | 1093/9788 [00:03<00:13, 635.80it/s] 12%|█▏        | 1158/9788 [00:03<00:13, 639.95it/s] 12%|█▏        | 1223/9788 [00:03<00:13, 642.13it/s] 13%|█▎        | 1288/9788 [00:03<00:13, 643.79it/s] 14%|█▍        | 1358/9788 [00:03<00:12, 660.26it/s] 15%|█▍        | 1425/9788 [00:03<00:13, 624.39it/s] 15%|█▌        | 1505/9788 [00:04<00:13, 636.15it/s] 16%|█▌        | 1581/9788 [00:04<00:12, 670.42it/s] 17%|█▋        | 1649/9788 [00:04<00:12, 632.44it/s] 18%|█▊        | 1713/9788 [00:04<00:12, 634.01it/s] 18%|█▊        | 1779/9788 [00:04<00:12, 641.11it/s] 19%|█▉        | 1844/9788 [00:04<00:12, 643.63it/s] 20%|█▉        | 1909/9788 [00:04<00:12, 644.95it/s] 20%|██        | 1975/9788 [00:04<00:12, 649.34it/s] 21%|██        | 2047/9788 [00:04<00:11, 669.95it/s] 22%|██▏       | 2115/9788 [00:04<00:12, 632.46it/s] 22%|██▏       | 2192/9788 [00:05<00:11, 671.50it/s] 23%|██▎       | 2260/9788 [00:05<00:11, 634.72it/s] 24%|██▍       | 2331/9788 [00:05<00:11, 655.70it/s] 25%|██▍       | 2401/9788 [00:05<00:11, 628.68it/s] 25%|██▌       | 2473/9788 [00:05<00:11, 653.85it/s] 26%|██▌       | 2541/9788 [00:05<00:10, 661.01it/s] 27%|██▋       | 2609/9788 [00:05<00:11, 626.73it/s] 27%|██▋       | 2680/9788 [00:05<00:10, 649.97it/s] 28%|██▊       | 2749/9788 [00:05<00:10, 661.24it/s] 29%|██▉       | 2817/9788 [00:06<00:11, 625.23it/s] 29%|██▉       | 2887/9788 [00:06<00:10, 645.93it/s] 30%|███       | 2960/9788 [00:06<00:10, 669.72it/s] 31%|███       | 3028/9788 [00:06<00:10, 635.99it/s] 32%|███▏      | 3105/9788 [00:06<00:10, 637.28it/s] 33%|███▎      | 3183/9788 [00:06<00:09, 676.45it/s] 33%|███▎      | 3252/9788 [00:06<00:10, 641.62it/s] 34%|███▍      | 3326/9788 [00:06<00:09, 668.55it/s] 35%|███▍      | 3394/9788 [00:06<00:10, 628.35it/s] 35%|███▌      | 3463/9788 [00:07<00:09, 645.03it/s] 36%|███▌      | 3534/9788 [00:07<00:09, 663.17it/s] 37%|███▋      | 3601/9788 [00:07<00:09, 626.32it/s] 38%|███▊      | 3672/9788 [00:07<00:09, 649.45it/s] 38%|███▊      | 3743/9788 [00:07<00:09, 666.52it/s] 39%|███▉      | 3811/9788 [00:07<00:09, 630.06it/s] 40%|███▉      | 3875/9788 [00:07<00:09, 631.63it/s] 40%|████      | 3950/9788 [00:07<00:08, 665.29it/s] 41%|████      | 4018/9788 [00:07<00:09, 630.36it/s] 42%|████▏     | 4092/9788 [00:08<00:08, 660.81it/s] 43%|████▎     | 4161/9788 [00:08<00:08, 630.64it/s] 43%|████▎     | 4236/9788 [00:08<00:08, 663.64it/s] 44%|████▍     | 4305/9788 [00:08<00:08, 632.56it/s] 45%|████▍     | 4370/9788 [00:08<00:08, 635.51it/s] 45%|████▌     | 4442/9788 [00:08<00:08, 659.29it/s] 46%|████▌     | 4513/9788 [00:08<00:08, 634.16it/s] 47%|████▋     | 4592/9788 [00:08<00:07, 677.38it/s] 48%|████▊     | 4661/9788 [00:08<00:07, 641.82it/s] 48%|████▊     | 4737/9788 [00:09<00:07, 636.33it/s] 49%|████▉     | 4815/9788 [00:09<00:07, 675.13it/s] 50%|████▉     | 4884/9788 [00:09<00:07, 637.70it/s] 51%|█████     | 4959/9788 [00:09<00:07, 668.13it/s] 51%|█████▏    | 5027/9788 [00:09<00:07, 633.92it/s] 52%|█████▏    | 5104/9788 [00:09<00:06, 671.00it/s] 53%|█████▎    | 5173/9788 [00:09<00:07, 639.67it/s] 54%|█████▎    | 5249/9788 [00:09<00:07, 634.94it/s] 54%|█████▍    | 5329/9788 [00:09<00:06, 642.19it/s] 55%|█████▌    | 5409/9788 [00:10<00:06, 646.61it/s] 56%|█████▌    | 5489/9788 [00:10<00:06, 649.92it/s] 57%|█████▋    | 5569/9788 [00:10<00:06, 652.04it/s] 58%|█████▊    | 5649/9788 [00:10<00:06, 654.80it/s] 59%|█████▊    | 5729/9788 [00:10<00:06, 658.89it/s] 59%|█████▉    | 5809/9788 [00:10<00:06, 662.27it/s] 60%|██████    | 5885/9788 [00:10<00:05, 687.95it/s] 61%|██████    | 5955/9788 [00:10<00:05, 658.07it/s] 62%|██████▏   | 6033/9788 [00:11<00:05, 654.96it/s] 62%|██████▏   | 6113/9788 [00:11<00:05, 658.30it/s] 63%|██████▎   | 6193/9788 [00:11<00:05, 660.07it/s] 64%|██████▍   | 6273/9788 [00:11<00:05, 660.86it/s] 65%|██████▍   | 6353/9788 [00:11<00:05, 661.61it/s] 66%|██████▌   | 6420/9788 [00:11<00:05, 663.43it/s] 66%|██████▋   | 6497/9788 [00:11<00:05, 656.08it/s] 67%|██████▋   | 6570/9788 [00:11<00:04, 675.93it/s] 68%|██████▊   | 6641/9788 [00:11<00:04, 650.80it/s] 69%|██████▊   | 6721/9788 [00:12<00:04, 657.52it/s] 69%|██████▉   | 6801/9788 [00:12<00:04, 664.54it/s] 70%|███████   | 6881/9788 [00:12<00:04, 669.95it/s] 71%|███████   | 6961/9788 [00:12<00:04, 671.88it/s] 72%|███████▏  | 7041/9788 [00:12<00:04, 671.57it/s] 73%|███████▎  | 7121/9788 [00:12<00:03, 672.80it/s] 74%|███████▎  | 7201/9788 [00:12<00:03, 673.38it/s] 74%|███████▍  | 7281/9788 [00:12<00:03, 672.25it/s] 75%|███████▌  | 7361/9788 [00:13<00:03, 671.14it/s] 76%|███████▌  | 7441/9788 [00:13<00:03, 670.74it/s] 77%|███████▋  | 7521/9788 [00:13<00:03, 670.56it/s] 78%|███████▊  | 7601/9788 [00:13<00:03, 671.76it/s] 78%|███████▊  | 7681/9788 [00:13<00:03, 672.59it/s] 79%|███████▉  | 7761/9788 [00:13<00:03, 675.55it/s] 80%|████████  | 7841/9788 [00:13<00:02, 676.65it/s] 81%|████████  | 7921/9788 [00:13<00:02, 676.44it/s] 82%|████████▏ | 8001/9788 [00:13<00:02, 675.38it/s] 83%|████████▎ | 8081/9788 [00:14<00:02, 674.56it/s] 83%|████████▎ | 8161/9788 [00:14<00:02, 674.13it/s] 84%|████████▍ | 8241/9788 [00:14<00:02, 674.18it/s] 85%|████████▌ | 8321/9788 [00:14<00:02, 675.39it/s] 86%|████████▌ | 8401/9788 [00:14<00:02, 675.84it/s] 87%|████████▋ | 8481/9788 [00:14<00:01, 675.74it/s] 87%|████████▋ | 8561/9788 [00:14<00:01, 675.61it/s] 88%|████████▊ | 8641/9788 [00:14<00:01, 674.79it/s] 89%|████████▉ | 8721/9788 [00:15<00:01, 675.45it/s] 90%|████████▉ | 8801/9788 [00:15<00:01, 674.18it/s] 91%|█████████ | 8881/9788 [00:15<00:01, 675.09it/s] 92%|█████████▏| 8961/9788 [00:15<00:01, 673.87it/s] 92%|█████████▏| 9041/9788 [00:15<00:01, 675.90it/s] 93%|█████████▎| 9121/9788 [00:15<00:00, 675.13it/s] 94%|█████████▍| 9201/9788 [00:15<00:00, 675.21it/s] 95%|█████████▍| 9281/9788 [00:15<00:00, 676.04it/s] 96%|█████████▌| 9361/9788 [00:15<00:00, 676.33it/s] 96%|█████████▋| 9441/9788 [00:16<00:00, 677.07it/s] 97%|█████████▋| 9521/9788 [00:16<00:00, 676.84it/s] 98%|█████████▊| 9601/9788 [00:16<00:00, 677.53it/s] 99%|█████████▉| 9681/9788 [00:16<00:00, 677.08it/s]100%|█████████▉| 9761/9788 [00:16<00:00, 673.76it/s]100%|██████████| 9788/9788 [00:16<00:00, 590.30it/s]
2024-01-16:01:10:54,158 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:01:10:54,158 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:01:10:54,158 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:01:10:54,158 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:01:10:54,158 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:01:10:54,158 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:01:10:54,158 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
2024-01-16:01:10:54,158 INFO     [evaluator.py:314] Running loglikelihood_rolling requests
  0%|          | 0/8 [00:00<?, ?it/s] 25%|██▌       | 2/8 [00:00<00:00,  6.85it/s] 38%|███▊      | 3/8 [00:00<00:00,  6.68it/s] 50%|█████     | 4/8 [00:00<00:00,  6.97it/s] 62%|██████▎   | 5/8 [00:00<00:00,  6.59it/s] 75%|███████▌  | 6/8 [00:00<00:00,  6.87it/s]100%|██████████| 8/8 [00:01<00:00,  9.44it/s]100%|██████████| 8/8 [00:01<00:00,  7.93it/s]
bootstrapping for stddev: perplexity
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<01:30,  1.09it/s]  2%|▏         | 2/100 [00:01<00:45,  2.16it/s]  5%|▌         | 5/100 [00:01<00:15,  6.12it/s] 99%|█████████▉| 99/100 [00:01<00:00, 134.36it/s]100%|██████████| 100/100 [00:01<00:00, 67.21it/s]
hf (pretrained=lomahony/pythia-160m-helpful-dpo), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 16
|    Tasks     |Version|Filter|n-shot|    Metric     | Value  |   |Stderr |
|--------------|------:|------|-----:|---------------|-------:|---|-------|
|arc_challenge |      1|none  |     0|acc            |  0.2125|±  | 0.0120|
|              |       |none  |     0|acc_norm       |  0.2312|±  | 0.0123|
|arc_easy      |      1|none  |     0|acc            |  0.3965|±  | 0.0100|
|              |       |none  |     0|acc_norm       |  0.3830|±  | 0.0100|
|boolq         |      2|none  |     0|acc            |  0.5853|±  | 0.0086|
|hellaswag     |      1|none  |     0|acc            |  0.2811|±  | 0.0045|
|              |       |none  |     0|acc_norm       |  0.2940|±  | 0.0045|
|lambada_openai|      1|none  |     0|perplexity     |444.4464|±  |24.5439|
|              |       |none  |     0|acc            |  0.1034|±  | 0.0042|
|openbookqa    |      1|none  |     0|acc            |  0.1500|±  | 0.0160|
|              |       |none  |     0|acc_norm       |  0.2480|±  | 0.0193|
|piqa          |      1|none  |     0|acc            |  0.5947|±  | 0.0115|
|              |       |none  |     0|acc_norm       |  0.5876|±  | 0.0115|
|sciq          |      1|none  |     0|acc            |  0.5880|±  | 0.0156|
|              |       |none  |     0|acc_norm       |  0.6180|±  | 0.0154|
|wikitext      |      2|none  |     0|word_perplexity| 88.8633|±  |N/A    |
|              |       |none  |     0|byte_perplexity|  2.3143|±  |N/A    |
|              |       |none  |     0|bits_per_byte  |  1.2106|±  |N/A    |
|winogrande    |      1|none  |     0|acc            |  0.4980|±  | 0.0141|

